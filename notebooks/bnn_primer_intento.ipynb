{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed4509bc-12b3-44c8-b8fe-d9fd2c15a0f6",
   "metadata": {},
   "source": [
    "# Probabilistic Bayesian Neural Networks\n",
    "https://keras.io/examples/keras_recipes/bayesian_neural_networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423fff56-3f9b-4e53-baa1-b0c914824414",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ed0b6-4b26-4c8e-bef4-edfa51780894",
   "metadata": {},
   "source": [
    "### Ambiente\n",
    "Creamos un ambiente con la paquetería necesaria\n",
    "\n",
    "``conda create -n env_tf_bayes``\n",
    "\n",
    "``conda activate env_tf_bayes``\n",
    "\n",
    "``pip install tensorflow-probability``\n",
    "\n",
    "``pip install tensorflow-datasets``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd76a638-eb0c-4d0b-8cf4-2bd7212040ad",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dff99bd0-ad24-4d72-b1f0-a9cacbe1636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352766fd-377b-4b38-81a8-c7eda67ab1c2",
   "metadata": {},
   "source": [
    "## Create training and evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2712abff-b5af-408f-96a1-6d9672dad5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test_splits(train_size, batch_size=1):\n",
    "    # Importar datos\n",
    "    data = pd.read_csv(\"./../data/train.csv\")\n",
    "\n",
    "    # Select the required columns\n",
    "    cols = [\n",
    "        'CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', \n",
    "        'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', \n",
    "        'EstimatedSalary', 'Exited'\n",
    "    ]\n",
    "    data = data[cols].copy()\n",
    "    # One-hot encode the 'Geography' column\n",
    "    data = pd.get_dummies(data, columns=['Geography'], prefix='Geo')\n",
    "\n",
    "    # Convert 'Gender' to boolean. \n",
    "    # Here we assume 'Male' maps to True and 'Female' to False.\n",
    "    data['Gender'] = data['Gender'].apply(lambda x: True if x == 'Male' else False)\n",
    "\n",
    "    # Convert other binary columns to boolean\n",
    "    bool_cols = ['HasCrCard', 'IsActiveMember', 'Exited']\n",
    "    data[bool_cols] = data[bool_cols].astype(bool)\n",
    "\n",
    "    # Ensure 'Age' is integer type\n",
    "    data['Age'] = data['Age'].astype(int)\n",
    "\n",
    "    # Scale 'Balance' and 'EstimatedSalary' using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    data[['Balance', 'EstimatedSalary']] = scaler.fit_transform(data[['Balance', 'EstimatedSalary']])\n",
    "    \n",
    "    # VARIABLE OBJETIVO Y VARIABLES INDEPENDIENTES\n",
    "    features = data.drop(columns=[\"Exited\"])\n",
    "    labels = data[\"Exited\"]\n",
    "\n",
    "    # Convertir a tensores de TensorFlow\n",
    "    features_dict = {col: tf.convert_to_tensor(features[col].values, dtype=tf.float32) for col in features.columns}\n",
    "    labels_tensor = tf.convert_to_tensor(labels.values, dtype=tf.float32)\n",
    "\n",
    "    # Crear dataset de TensorFlow\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features_dict, labels_tensor))\n",
    "    dataset = dataset.cache().shuffle(len(data)).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Definir train_size y test_size correctamente\n",
    "    test_size = len(data) - train_size  # Corregir tamaño del dataset de prueba\n",
    "\n",
    "    train_dataset = dataset.take(train_size).batch(batch_size)\n",
    "    test_dataset = dataset.skip(train_size).take(test_size).batch(batch_size)  # Agregar `take(test_size)`\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8461559-0e90-4544-b5b1-3d8e8ac6e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./../data/train.csv\")\n",
    "dataset_size = data.shape[0]\n",
    "batch_size = 256\n",
    "train_size = int(dataset_size * 0.85)\n",
    "train_dataset, test_dataset = get_train_and_test_splits(train_size, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2010149e-dd28-4b75-8285-f5c200af8974",
   "metadata": {},
   "source": [
    "## Compile, train, and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b401298f-9c6c-484a-9134-d84a11ba4702",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = [8, 8]\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "def run_experiment(model, loss, train_dataset, test_dataset):\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "        loss=loss,\n",
    "        metrics=['accuracy', tf.keras.metrics.Recall()]\n",
    "    )\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=100,\n",
    "        validation_data=test_dataset,\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"Model training finished.\")\n",
    "\n",
    "    print(\"Evaluating model performance...\")\n",
    "    test_loss, test_accuracy, test_recall = model.evaluate(test_dataset, verbose=1)\n",
    "    print('Test Accuracy: {:.2f}%'.format(test_accuracy * 100))\n",
    "    print('Test Recall: {:.2f}%'.format(test_recall * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6681bc6a-9c4b-467b-8bf8-4e07d7510051",
   "metadata": {},
   "source": [
    "## Create model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "582d7b4d-811b-4b3e-8295-ebcd92c96299",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_NAMES = [\n",
    "    'CreditScore', \n",
    "    'Gender', \n",
    "    'Age', \n",
    "    'Tenure', \n",
    "    'Balance', \n",
    "    'NumOfProducts', \n",
    "    'HasCrCard', \n",
    "    'IsActiveMember', \n",
    "    'EstimatedSalary', \n",
    "    'Geo_France', \n",
    "    'Geo_Germany', \n",
    "    'Geo_Spain'\n",
    "]\n",
    "\n",
    "\n",
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        inputs[feature_name] = layers.Input(\n",
    "            name=feature_name, shape=(1,), dtype=tf.float32\n",
    "        )\n",
    "    return inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dcde19-1e82-45a8-a07b-4b98f159c1c8",
   "metadata": {},
   "source": [
    "## Experiment 1: standard neural network\n",
    "We create a standard deterministic neural network model as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c027c0d3-2544-4450-b8e5-d40352cbf7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_model():\n",
    "    inputs = create_model_inputs()\n",
    "    input_values = [value for _, value in sorted(inputs.items())]\n",
    "    x = keras.layers.concatenate(input_values)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Equivalent layers to the Sequential model\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(16, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Output layer with sigmoid for binary classification\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030848d0-0581-4ba6-b4eb-4d119081404b",
   "metadata": {},
   "source": [
    "Let's split the wine dataset into training and test sets, with 85% and 15% of the examples, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b87fe715-722f-4aae-932a-181b1d7e1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./../data/train.csv\")\n",
    "dataset_size = data.shape[0]\n",
    "batch_size = 256\n",
    "train_size = int(dataset_size * 0.85)\n",
    "train_dataset, test_dataset = get_train_and_test_splits(train_size, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26dd921-5d67-4c74-ae1b-958fe7027957",
   "metadata": {},
   "source": [
    "Now let's train the baseline model. We use the MeanSquaredError as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4eccc3ca-c75c-4892-94cf-e5551765c5b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 20:25:04.160043: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [165034]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2025-04-15 20:25:04.160513: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype float and shape [165034]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548/548 [==============================] - ETA: 0s - loss: 0.5868 - accuracy: 0.7051 - recall_2: 0.1911"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 20:25:10.479451: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype float and shape [165034]\n",
      "\t [[{{node Placeholder/_9}}]]\n",
      "2025-04-15 20:25:10.481140: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_7' with dtype float and shape [165034]\n",
      "\t [[{{node Placeholder/_7}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548/548 [==============================] - 8s 11ms/step - loss: 0.5868 - accuracy: 0.7051 - recall_2: 0.1911 - val_loss: 0.4421 - val_accuracy: 0.7876 - val_recall_2: 0.0000e+00\n",
      "Epoch 2/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.4901 - accuracy: 0.7889 - recall_2: 0.0831 - val_loss: 0.4178 - val_accuracy: 0.8058 - val_recall_2: 0.1181\n",
      "Epoch 3/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.4664 - accuracy: 0.7987 - recall_2: 0.1352 - val_loss: 0.3999 - val_accuracy: 0.8307 - val_recall_2: 0.2710\n",
      "Epoch 4/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.4509 - accuracy: 0.8061 - recall_2: 0.1810 - val_loss: 0.3901 - val_accuracy: 0.8380 - val_recall_2: 0.3700\n",
      "Epoch 5/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.4400 - accuracy: 0.8110 - recall_2: 0.2198 - val_loss: 0.3852 - val_accuracy: 0.8443 - val_recall_2: 0.4177\n",
      "Epoch 6/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.4325 - accuracy: 0.8148 - recall_2: 0.2547 - val_loss: 0.3864 - val_accuracy: 0.8408 - val_recall_2: 0.4232\n",
      "Epoch 7/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.4232 - accuracy: 0.8187 - recall_2: 0.2756 - val_loss: 0.3779 - val_accuracy: 0.8426 - val_recall_2: 0.4434\n",
      "Epoch 8/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.4181 - accuracy: 0.8220 - recall_2: 0.3038 - val_loss: 0.3676 - val_accuracy: 0.8510 - val_recall_2: 0.4499\n",
      "Epoch 9/100\n",
      "548/548 [==============================] - 8s 13ms/step - loss: 0.4128 - accuracy: 0.8235 - recall_2: 0.3170 - val_loss: 0.3692 - val_accuracy: 0.8483 - val_recall_2: 0.4409\n",
      "Epoch 10/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.4066 - accuracy: 0.8274 - recall_2: 0.3342 - val_loss: 0.3607 - val_accuracy: 0.8507 - val_recall_2: 0.4441\n",
      "Epoch 11/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3997 - accuracy: 0.8291 - recall_2: 0.3477 - val_loss: 0.3640 - val_accuracy: 0.8471 - val_recall_2: 0.4577\n",
      "Epoch 12/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.3957 - accuracy: 0.8321 - recall_2: 0.3672 - val_loss: 0.3522 - val_accuracy: 0.8536 - val_recall_2: 0.4662\n",
      "Epoch 13/100\n",
      "548/548 [==============================] - 8s 13ms/step - loss: 0.3909 - accuracy: 0.8337 - recall_2: 0.3785 - val_loss: 0.3494 - val_accuracy: 0.8574 - val_recall_2: 0.4677\n",
      "Epoch 14/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.3875 - accuracy: 0.8352 - recall_2: 0.3842 - val_loss: 0.3521 - val_accuracy: 0.8568 - val_recall_2: 0.4754\n",
      "Epoch 15/100\n",
      "548/548 [==============================] - 8s 13ms/step - loss: 0.3864 - accuracy: 0.8365 - recall_2: 0.3899 - val_loss: 0.3445 - val_accuracy: 0.8578 - val_recall_2: 0.4689\n",
      "Epoch 16/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3831 - accuracy: 0.8385 - recall_2: 0.4009 - val_loss: 0.3430 - val_accuracy: 0.8597 - val_recall_2: 0.4892\n",
      "Epoch 17/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.3792 - accuracy: 0.8404 - recall_2: 0.4068 - val_loss: 0.3358 - val_accuracy: 0.8650 - val_recall_2: 0.4826\n",
      "Epoch 18/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3759 - accuracy: 0.8417 - recall_2: 0.4116 - val_loss: 0.3393 - val_accuracy: 0.8602 - val_recall_2: 0.4842\n",
      "Epoch 19/100\n",
      "548/548 [==============================] - 8s 15ms/step - loss: 0.3750 - accuracy: 0.8426 - recall_2: 0.4201 - val_loss: 0.3419 - val_accuracy: 0.8585 - val_recall_2: 0.4604\n",
      "Epoch 20/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.3724 - accuracy: 0.8443 - recall_2: 0.4233 - val_loss: 0.3444 - val_accuracy: 0.8544 - val_recall_2: 0.4552\n",
      "Epoch 21/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3734 - accuracy: 0.8449 - recall_2: 0.4294 - val_loss: 0.3480 - val_accuracy: 0.8543 - val_recall_2: 0.4684\n",
      "Epoch 22/100\n",
      "548/548 [==============================] - 8s 15ms/step - loss: 0.3704 - accuracy: 0.8458 - recall_2: 0.4275 - val_loss: 0.3430 - val_accuracy: 0.8566 - val_recall_2: 0.4664\n",
      "Epoch 23/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3690 - accuracy: 0.8462 - recall_2: 0.4293 - val_loss: 0.3342 - val_accuracy: 0.8625 - val_recall_2: 0.4663\n",
      "Epoch 24/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3687 - accuracy: 0.8471 - recall_2: 0.4353 - val_loss: 0.3304 - val_accuracy: 0.8641 - val_recall_2: 0.4590\n",
      "Epoch 25/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3669 - accuracy: 0.8471 - recall_2: 0.4362 - val_loss: 0.3324 - val_accuracy: 0.8643 - val_recall_2: 0.4643\n",
      "Epoch 26/100\n",
      "548/548 [==============================] - 8s 13ms/step - loss: 0.3682 - accuracy: 0.8467 - recall_2: 0.4352 - val_loss: 0.3339 - val_accuracy: 0.8602 - val_recall_2: 0.4532\n",
      "Epoch 27/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3646 - accuracy: 0.8489 - recall_2: 0.4444 - val_loss: 0.3350 - val_accuracy: 0.8613 - val_recall_2: 0.4560\n",
      "Epoch 28/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.3668 - accuracy: 0.8481 - recall_2: 0.4382 - val_loss: 0.3299 - val_accuracy: 0.8627 - val_recall_2: 0.4590\n",
      "Epoch 29/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3656 - accuracy: 0.8490 - recall_2: 0.4414 - val_loss: 0.3382 - val_accuracy: 0.8579 - val_recall_2: 0.4494\n",
      "Epoch 30/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3640 - accuracy: 0.8495 - recall_2: 0.4448 - val_loss: 0.3350 - val_accuracy: 0.8616 - val_recall_2: 0.4723\n",
      "Epoch 31/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3630 - accuracy: 0.8501 - recall_2: 0.4460 - val_loss: 0.3263 - val_accuracy: 0.8637 - val_recall_2: 0.4762\n",
      "Epoch 32/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3621 - accuracy: 0.8508 - recall_2: 0.4505 - val_loss: 0.3318 - val_accuracy: 0.8596 - val_recall_2: 0.4642\n",
      "Epoch 33/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3624 - accuracy: 0.8506 - recall_2: 0.4532 - val_loss: 0.3329 - val_accuracy: 0.8616 - val_recall_2: 0.4686\n",
      "Epoch 34/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3608 - accuracy: 0.8511 - recall_2: 0.4528 - val_loss: 0.3347 - val_accuracy: 0.8599 - val_recall_2: 0.4726\n",
      "Epoch 35/100\n",
      "548/548 [==============================] - 8s 13ms/step - loss: 0.3613 - accuracy: 0.8521 - recall_2: 0.4601 - val_loss: 0.3327 - val_accuracy: 0.8643 - val_recall_2: 0.4760\n",
      "Epoch 36/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.3603 - accuracy: 0.8514 - recall_2: 0.4524 - val_loss: 0.3294 - val_accuracy: 0.8627 - val_recall_2: 0.4682\n",
      "Epoch 37/100\n",
      "548/548 [==============================] - 9s 15ms/step - loss: 0.3608 - accuracy: 0.8511 - recall_2: 0.4519 - val_loss: 0.3346 - val_accuracy: 0.8587 - val_recall_2: 0.4642\n",
      "Epoch 38/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3597 - accuracy: 0.8515 - recall_2: 0.4558 - val_loss: 0.3326 - val_accuracy: 0.8593 - val_recall_2: 0.4743\n",
      "Epoch 39/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.3600 - accuracy: 0.8513 - recall_2: 0.4560 - val_loss: 0.3346 - val_accuracy: 0.8585 - val_recall_2: 0.4667\n",
      "Epoch 40/100\n",
      "548/548 [==============================] - 8s 13ms/step - loss: 0.3587 - accuracy: 0.8521 - recall_2: 0.4591 - val_loss: 0.3275 - val_accuracy: 0.8650 - val_recall_2: 0.4810\n",
      "Epoch 41/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3595 - accuracy: 0.8516 - recall_2: 0.4598 - val_loss: 0.3295 - val_accuracy: 0.8633 - val_recall_2: 0.4655\n",
      "Epoch 42/100\n",
      "548/548 [==============================] - 8s 13ms/step - loss: 0.3576 - accuracy: 0.8526 - recall_2: 0.4584 - val_loss: 0.3368 - val_accuracy: 0.8607 - val_recall_2: 0.4650\n",
      "Epoch 43/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3589 - accuracy: 0.8514 - recall_2: 0.4569 - val_loss: 0.3332 - val_accuracy: 0.8578 - val_recall_2: 0.4710\n",
      "Epoch 44/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3576 - accuracy: 0.8525 - recall_2: 0.4556 - val_loss: 0.3324 - val_accuracy: 0.8620 - val_recall_2: 0.4794\n",
      "Epoch 45/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3568 - accuracy: 0.8519 - recall_2: 0.4582 - val_loss: 0.3321 - val_accuracy: 0.8610 - val_recall_2: 0.4831\n",
      "Epoch 46/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.3570 - accuracy: 0.8528 - recall_2: 0.4644 - val_loss: 0.3327 - val_accuracy: 0.8616 - val_recall_2: 0.4721\n",
      "Epoch 47/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3592 - accuracy: 0.8512 - recall_2: 0.4564 - val_loss: 0.3276 - val_accuracy: 0.8648 - val_recall_2: 0.4864\n",
      "Epoch 48/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3573 - accuracy: 0.8530 - recall_2: 0.4586 - val_loss: 0.3295 - val_accuracy: 0.8604 - val_recall_2: 0.4749\n",
      "Epoch 49/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3559 - accuracy: 0.8521 - recall_2: 0.4597 - val_loss: 0.3323 - val_accuracy: 0.8601 - val_recall_2: 0.4815\n",
      "Epoch 50/100\n",
      "548/548 [==============================] - 9s 15ms/step - loss: 0.3572 - accuracy: 0.8527 - recall_2: 0.4640 - val_loss: 0.3264 - val_accuracy: 0.8633 - val_recall_2: 0.4928\n",
      "Epoch 51/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3573 - accuracy: 0.8532 - recall_2: 0.4623 - val_loss: 0.3296 - val_accuracy: 0.8605 - val_recall_2: 0.4733\n",
      "Epoch 52/100\n",
      "548/548 [==============================] - 8s 13ms/step - loss: 0.3568 - accuracy: 0.8533 - recall_2: 0.4594 - val_loss: 0.3334 - val_accuracy: 0.8585 - val_recall_2: 0.4685\n",
      "Epoch 53/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.3559 - accuracy: 0.8529 - recall_2: 0.4621 - val_loss: 0.3241 - val_accuracy: 0.8655 - val_recall_2: 0.4956\n",
      "Epoch 54/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3549 - accuracy: 0.8529 - recall_2: 0.4662 - val_loss: 0.3290 - val_accuracy: 0.8642 - val_recall_2: 0.4804\n",
      "Epoch 55/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3566 - accuracy: 0.8532 - recall_2: 0.4626 - val_loss: 0.3253 - val_accuracy: 0.8633 - val_recall_2: 0.4822\n",
      "Epoch 56/100\n",
      "548/548 [==============================] - 8s 15ms/step - loss: 0.3555 - accuracy: 0.8534 - recall_2: 0.4674 - val_loss: 0.3269 - val_accuracy: 0.8640 - val_recall_2: 0.4816\n",
      "Epoch 57/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.3551 - accuracy: 0.8525 - recall_2: 0.4645 - val_loss: 0.3315 - val_accuracy: 0.8604 - val_recall_2: 0.4786\n",
      "Epoch 58/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.3549 - accuracy: 0.8527 - recall_2: 0.4631 - val_loss: 0.3268 - val_accuracy: 0.8630 - val_recall_2: 0.4704\n",
      "Epoch 59/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.3543 - accuracy: 0.8530 - recall_2: 0.4666 - val_loss: 0.3349 - val_accuracy: 0.8584 - val_recall_2: 0.4752\n",
      "Epoch 60/100\n",
      "548/548 [==============================] - 8s 15ms/step - loss: 0.3544 - accuracy: 0.8531 - recall_2: 0.4658 - val_loss: 0.3254 - val_accuracy: 0.8640 - val_recall_2: 0.4877\n",
      "Epoch 61/100\n",
      "548/548 [==============================] - 8s 13ms/step - loss: 0.3545 - accuracy: 0.8519 - recall_2: 0.4650 - val_loss: 0.3295 - val_accuracy: 0.8613 - val_recall_2: 0.4929\n",
      "Epoch 62/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3542 - accuracy: 0.8535 - recall_2: 0.4679 - val_loss: 0.3272 - val_accuracy: 0.8605 - val_recall_2: 0.4736\n",
      "Epoch 63/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.3539 - accuracy: 0.8537 - recall_2: 0.4686 - val_loss: 0.3287 - val_accuracy: 0.8615 - val_recall_2: 0.4664\n",
      "Epoch 64/100\n",
      "548/548 [==============================] - 10s 18ms/step - loss: 0.3544 - accuracy: 0.8536 - recall_2: 0.4619 - val_loss: 0.3307 - val_accuracy: 0.8585 - val_recall_2: 0.4700\n",
      "Epoch 65/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3556 - accuracy: 0.8528 - recall_2: 0.4639 - val_loss: 0.3312 - val_accuracy: 0.8602 - val_recall_2: 0.4759\n",
      "Epoch 66/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3535 - accuracy: 0.8533 - recall_2: 0.4649 - val_loss: 0.3274 - val_accuracy: 0.8635 - val_recall_2: 0.4869\n",
      "Epoch 67/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3530 - accuracy: 0.8538 - recall_2: 0.4706 - val_loss: 0.3256 - val_accuracy: 0.8620 - val_recall_2: 0.4878\n",
      "Epoch 68/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3546 - accuracy: 0.8533 - recall_2: 0.4663 - val_loss: 0.3236 - val_accuracy: 0.8633 - val_recall_2: 0.4901\n",
      "Epoch 69/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3540 - accuracy: 0.8544 - recall_2: 0.4728 - val_loss: 0.3282 - val_accuracy: 0.8612 - val_recall_2: 0.4844\n",
      "Epoch 70/100\n",
      "548/548 [==============================] - 10s 18ms/step - loss: 0.3529 - accuracy: 0.8541 - recall_2: 0.4699 - val_loss: 0.3286 - val_accuracy: 0.8625 - val_recall_2: 0.4945\n",
      "Epoch 71/100\n",
      "548/548 [==============================] - 10s 17ms/step - loss: 0.3514 - accuracy: 0.8537 - recall_2: 0.4647 - val_loss: 0.3319 - val_accuracy: 0.8592 - val_recall_2: 0.4830\n",
      "Epoch 72/100\n",
      "548/548 [==============================] - 9s 16ms/step - loss: 0.3509 - accuracy: 0.8544 - recall_2: 0.4716 - val_loss: 0.3316 - val_accuracy: 0.8614 - val_recall_2: 0.4944\n",
      "Epoch 73/100\n",
      "548/548 [==============================] - 10s 17ms/step - loss: 0.3511 - accuracy: 0.8546 - recall_2: 0.4727 - val_loss: 0.3229 - val_accuracy: 0.8651 - val_recall_2: 0.5094\n",
      "Epoch 74/100\n",
      "548/548 [==============================] - 10s 17ms/step - loss: 0.3515 - accuracy: 0.8549 - recall_2: 0.4754 - val_loss: 0.3368 - val_accuracy: 0.8576 - val_recall_2: 0.4858\n",
      "Epoch 75/100\n",
      "548/548 [==============================] - 10s 17ms/step - loss: 0.3522 - accuracy: 0.8543 - recall_2: 0.4696 - val_loss: 0.3267 - val_accuracy: 0.8636 - val_recall_2: 0.4948\n",
      "Epoch 76/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3507 - accuracy: 0.8551 - recall_2: 0.4746 - val_loss: 0.3278 - val_accuracy: 0.8621 - val_recall_2: 0.4882\n",
      "Epoch 77/100\n",
      "548/548 [==============================] - 9s 15ms/step - loss: 0.3522 - accuracy: 0.8538 - recall_2: 0.4713 - val_loss: 0.3284 - val_accuracy: 0.8587 - val_recall_2: 0.4822\n",
      "Epoch 78/100\n",
      "548/548 [==============================] - 9s 15ms/step - loss: 0.3519 - accuracy: 0.8553 - recall_2: 0.4752 - val_loss: 0.3250 - val_accuracy: 0.8652 - val_recall_2: 0.4958\n",
      "Epoch 79/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3529 - accuracy: 0.8529 - recall_2: 0.4660 - val_loss: 0.3278 - val_accuracy: 0.8605 - val_recall_2: 0.4893\n",
      "Epoch 80/100\n",
      "548/548 [==============================] - 9s 16ms/step - loss: 0.3519 - accuracy: 0.8541 - recall_2: 0.4711 - val_loss: 0.3243 - val_accuracy: 0.8621 - val_recall_2: 0.4943\n",
      "Epoch 81/100\n",
      "548/548 [==============================] - 10s 17ms/step - loss: 0.3522 - accuracy: 0.8536 - recall_2: 0.4712 - val_loss: 0.3261 - val_accuracy: 0.8629 - val_recall_2: 0.5073\n",
      "Epoch 82/100\n",
      "548/548 [==============================] - 9s 15ms/step - loss: 0.3533 - accuracy: 0.8535 - recall_2: 0.4680 - val_loss: 0.3270 - val_accuracy: 0.8619 - val_recall_2: 0.4856\n",
      "Epoch 83/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3509 - accuracy: 0.8545 - recall_2: 0.4685 - val_loss: 0.3256 - val_accuracy: 0.8631 - val_recall_2: 0.4984\n",
      "Epoch 84/100\n",
      "548/548 [==============================] - 9s 15ms/step - loss: 0.3510 - accuracy: 0.8551 - recall_2: 0.4756 - val_loss: 0.3257 - val_accuracy: 0.8636 - val_recall_2: 0.4917\n",
      "Epoch 85/100\n",
      "548/548 [==============================] - 10s 18ms/step - loss: 0.3506 - accuracy: 0.8539 - recall_2: 0.4712 - val_loss: 0.3291 - val_accuracy: 0.8598 - val_recall_2: 0.4950\n",
      "Epoch 86/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3501 - accuracy: 0.8546 - recall_2: 0.4747 - val_loss: 0.3334 - val_accuracy: 0.8577 - val_recall_2: 0.4924\n",
      "Epoch 87/100\n",
      "548/548 [==============================] - 9s 15ms/step - loss: 0.3532 - accuracy: 0.8542 - recall_2: 0.4730 - val_loss: 0.3294 - val_accuracy: 0.8614 - val_recall_2: 0.4998\n",
      "Epoch 88/100\n",
      "548/548 [==============================] - 9s 16ms/step - loss: 0.3524 - accuracy: 0.8536 - recall_2: 0.4728 - val_loss: 0.3232 - val_accuracy: 0.8650 - val_recall_2: 0.5058\n",
      "Epoch 89/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3523 - accuracy: 0.8530 - recall_2: 0.4710 - val_loss: 0.3223 - val_accuracy: 0.8650 - val_recall_2: 0.5061\n",
      "Epoch 90/100\n",
      "548/548 [==============================] - 10s 17ms/step - loss: 0.3533 - accuracy: 0.8532 - recall_2: 0.4719 - val_loss: 0.3312 - val_accuracy: 0.8589 - val_recall_2: 0.4903\n",
      "Epoch 91/100\n",
      "548/548 [==============================] - 10s 17ms/step - loss: 0.3522 - accuracy: 0.8554 - recall_2: 0.4744 - val_loss: 0.3320 - val_accuracy: 0.8587 - val_recall_2: 0.4894\n",
      "Epoch 92/100\n",
      "548/548 [==============================] - 9s 15ms/step - loss: 0.3514 - accuracy: 0.8553 - recall_2: 0.4737 - val_loss: 0.3253 - val_accuracy: 0.8627 - val_recall_2: 0.5160\n",
      "Epoch 93/100\n",
      "548/548 [==============================] - 10s 17ms/step - loss: 0.3510 - accuracy: 0.8550 - recall_2: 0.4747 - val_loss: 0.3250 - val_accuracy: 0.8635 - val_recall_2: 0.5056\n",
      "Epoch 94/100\n",
      "548/548 [==============================] - 11s 18ms/step - loss: 0.3506 - accuracy: 0.8553 - recall_2: 0.4747 - val_loss: 0.3255 - val_accuracy: 0.8646 - val_recall_2: 0.5145\n",
      "Epoch 95/100\n",
      "548/548 [==============================] - 10s 18ms/step - loss: 0.3520 - accuracy: 0.8547 - recall_2: 0.4730 - val_loss: 0.3197 - val_accuracy: 0.8677 - val_recall_2: 0.5176\n",
      "Epoch 96/100\n",
      "548/548 [==============================] - 10s 17ms/step - loss: 0.3509 - accuracy: 0.8544 - recall_2: 0.4733 - val_loss: 0.3266 - val_accuracy: 0.8621 - val_recall_2: 0.5014\n",
      "Epoch 97/100\n",
      "548/548 [==============================] - 9s 16ms/step - loss: 0.3515 - accuracy: 0.8556 - recall_2: 0.4785 - val_loss: 0.3249 - val_accuracy: 0.8636 - val_recall_2: 0.5098\n",
      "Epoch 98/100\n",
      "548/548 [==============================] - 11s 20ms/step - loss: 0.3514 - accuracy: 0.8546 - recall_2: 0.4706 - val_loss: 0.3213 - val_accuracy: 0.8654 - val_recall_2: 0.5043\n",
      "Epoch 99/100\n",
      "548/548 [==============================] - 10s 18ms/step - loss: 0.3503 - accuracy: 0.8546 - recall_2: 0.4754 - val_loss: 0.3317 - val_accuracy: 0.8602 - val_recall_2: 0.4989\n",
      "Epoch 100/100\n",
      "548/548 [==============================] - 9s 15ms/step - loss: 0.3502 - accuracy: 0.8549 - recall_2: 0.4729 - val_loss: 0.3262 - val_accuracy: 0.8636 - val_recall_2: 0.5111\n",
      "Model training finished.\n",
      "Evaluating model performance...\n",
      "97/97 [==============================] - 2s 6ms/step - loss: 0.3318 - accuracy: 0.8602 - recall_2: 0.4934\n",
      "Test Accuracy: 86.02%\n",
      "Test Recall: 49.34%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "bce_loss = keras.losses.BinaryCrossentropy()\n",
    "baseline_model = create_baseline_model()\n",
    "run_experiment(baseline_model, bce_loss, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24ebfdd-2c65-433e-a57e-d1fa1b79e48c",
   "metadata": {},
   "source": [
    "We take a sample from the test set use the model to obtain predictions for them. Note that since the baseline model is deterministic, we get a single a point estimate prediction for each test example, with no information about the uncertainty of the model nor the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca262b29-cf2d-4c39-a9a4-3b9c670a3dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 20:38:30.654043: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype float and shape [165034]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2025-04-15 20:38:30.656280: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_12' with dtype float and shape [165034]\n",
      "\t [[{{node Placeholder/_12}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0.0 - Actual: 0.0\n",
      "Predicted: 0.2 - Actual: 0.0\n",
      "Predicted: 0.2 - Actual: 0.0\n",
      "Predicted: 0.0 - Actual: 0.0\n",
      "Predicted: 0.3 - Actual: 0.0\n",
      "Predicted: 0.1 - Actual: 0.0\n",
      "Predicted: 0.1 - Actual: 0.0\n",
      "Predicted: 0.1 - Actual: 0.0\n",
      "Predicted: 0.0 - Actual: 0.0\n",
      "Predicted: 0.5 - Actual: 1.0\n"
     ]
    }
   ],
   "source": [
    "sample = 10\n",
    "examples, targets = list(test_dataset.unbatch().shuffle(batch_size * 10).batch(sample))[\n",
    "    0\n",
    "]\n",
    "\n",
    "predicted = baseline_model(examples).numpy()\n",
    "for idx in range(sample):\n",
    "    print(f\"Predicted: {round(float(predicted[idx][0]), 1)} - Actual: {targets[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe2f284-a339-45a7-ae35-2cf3201f33ff",
   "metadata": {},
   "source": [
    "## Experiment 2: Bayesian neural network (BNN)\n",
    "\n",
    "The object of the Bayesian approach for modeling neural networks is to capture the epistemic uncertainty, which is uncertainty about the model fitness, due to limited training data.\n",
    "\n",
    "The idea is that, instead of learning specific weight (and bias) values in the neural network, the Bayesian approach learns weight distributions - from which we can sample to produce an output for a given input - to encode weight uncertainty.\n",
    "\n",
    "Thus, we need to define prior and the posterior distributions of these weights, and the training process is to learn the parameters of these distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1bc6068-c1ac-416c-81f8-44a18a506e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prior weight distribution as Normal of mean=0 and stddev=1.\n",
    "# Note that, in this example, the we prior distribution is not trainable,\n",
    "# as we fix its parameters.\n",
    "def prior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    prior_model = keras.Sequential(\n",
    "        [\n",
    "            tfp.layers.DistributionLambda(\n",
    "                lambda t: tfp.distributions.MultivariateNormalDiag(\n",
    "                    loc=tf.zeros(n), scale_diag=tf.ones(n)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return prior_model\n",
    "\n",
    "\n",
    "# Define variational posterior weight distribution as multivariate Gaussian.\n",
    "# Note that the learnable parameters for this distribution are the means,\n",
    "# variances, and covariances.\n",
    "def posterior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    posterior_model = keras.Sequential(\n",
    "        [\n",
    "            tfp.layers.VariableLayer(\n",
    "                tfp.layers.MultivariateNormalTriL.params_size(n), dtype=dtype\n",
    "            ),\n",
    "            tfp.layers.MultivariateNormalTriL(n),\n",
    "        ]\n",
    "    )\n",
    "    return posterior_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c424fd-0b0f-41ca-93d4-d20c69d50ef1",
   "metadata": {},
   "source": [
    "We use the tfp.layers.DenseVariational layer instead of the standard keras.layers.Dense layer in the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ed2328d-2011-484b-8c2f-e8b2f8ddcf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_bnn_model(train_size):\n",
    "    inputs = create_model_inputs()\n",
    "    features = keras.layers.concatenate(list(inputs.values()))\n",
    "    features = layers.BatchNormalization()(features)\n",
    "\n",
    "    # Create hidden layers with weight uncertainty using the DenseVariational layer.\n",
    "    for units in hidden_units:\n",
    "        features = tfp.layers.DenseVariational(\n",
    "            units=units,\n",
    "            make_prior_fn=prior,\n",
    "            make_posterior_fn=posterior,\n",
    "            kl_weight=1 / train_size,\n",
    "            activation=\"sigmoid\",\n",
    "        )(features)\n",
    "\n",
    "    # The output is deterministic: a single point estimate.\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb86cf0-3710-410c-9eb8-ff11cf10f06d",
   "metadata": {},
   "source": [
    "The epistemic uncertainty can be reduced as we increase the size of the training data. That is, the more data the BNN model sees, the more it is certain about its estimates for the weights (distribution parameters). Let's test this behaviour by training the BNN model on a small subset of the training set, and then on the full training set, to compare the output variances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053b8cc8-d151-4fac-a084-be31e9f88cd2",
   "metadata": {},
   "source": [
    "### Train BNN with a small training subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6089a28b-9527-4e8b-b3c8-137e4127e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 20:38:33.124248: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [165034]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-04-15 20:38:33.124904: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_12' with dtype float and shape [165034]\n",
      "\t [[{{node Placeholder/_12}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 6s 23ms/step - loss: 0.5343 - accuracy: 0.7864 - recall_3: 0.0000e+00 - val_loss: 0.5353 - val_accuracy: 0.7848 - val_recall_3: 0.0000e+00\n",
      "Epoch 2/100\n",
      "165/165 [==============================] - 3s 19ms/step - loss: 0.5349 - accuracy: 0.7858 - recall_3: 0.0013 - val_loss: 0.5226 - val_accuracy: 0.7928 - val_recall_3: 0.0000e+00\n",
      "Epoch 3/100\n",
      "165/165 [==============================] - 5s 26ms/step - loss: 0.5211 - accuracy: 0.7927 - recall_3: 0.0000e+00 - val_loss: 0.5254 - val_accuracy: 0.7887 - val_recall_3: 0.0000e+00\n",
      "Epoch 4/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.5245 - accuracy: 0.7890 - recall_3: 0.0000e+00 - val_loss: 0.5225 - val_accuracy: 0.7898 - val_recall_3: 0.0000e+00\n",
      "Epoch 5/100\n",
      "165/165 [==============================] - 4s 19ms/step - loss: 0.5257 - accuracy: 0.7894 - recall_3: 0.0000e+00 - val_loss: 0.5232 - val_accuracy: 0.7895 - val_recall_3: 0.0000e+00\n",
      "Epoch 6/100\n",
      "165/165 [==============================] - 3s 19ms/step - loss: 0.5269 - accuracy: 0.7854 - recall_3: 0.0000e+00 - val_loss: 0.5218 - val_accuracy: 0.7900 - val_recall_3: 0.0000e+00\n",
      "Epoch 7/100\n",
      "165/165 [==============================] - 4s 24ms/step - loss: 0.5249 - accuracy: 0.7886 - recall_3: 0.0000e+00 - val_loss: 0.5250 - val_accuracy: 0.7871 - val_recall_3: 0.0000e+00\n",
      "Epoch 8/100\n",
      "165/165 [==============================] - 4s 24ms/step - loss: 0.5217 - accuracy: 0.7895 - recall_3: 0.0000e+00 - val_loss: 0.5143 - val_accuracy: 0.7925 - val_recall_3: 0.0000e+00\n",
      "Epoch 9/100\n",
      "165/165 [==============================] - 4s 22ms/step - loss: 0.5250 - accuracy: 0.7872 - recall_3: 0.0000e+00 - val_loss: 0.5184 - val_accuracy: 0.7909 - val_recall_3: 0.0000e+00\n",
      "Epoch 10/100\n",
      "165/165 [==============================] - 4s 24ms/step - loss: 0.5226 - accuracy: 0.7890 - recall_3: 0.0000e+00 - val_loss: 0.5239 - val_accuracy: 0.7869 - val_recall_3: 0.0000e+00\n",
      "Epoch 11/100\n",
      "165/165 [==============================] - 4s 22ms/step - loss: 0.5215 - accuracy: 0.7889 - recall_3: 0.0000e+00 - val_loss: 0.5189 - val_accuracy: 0.7908 - val_recall_3: 0.0000e+00\n",
      "Epoch 12/100\n",
      "165/165 [==============================] - 3s 19ms/step - loss: 0.5223 - accuracy: 0.7885 - recall_3: 0.0000e+00 - val_loss: 0.5231 - val_accuracy: 0.7867 - val_recall_3: 0.0000e+00\n",
      "Epoch 13/100\n",
      "165/165 [==============================] - 4s 22ms/step - loss: 0.5233 - accuracy: 0.7874 - recall_3: 0.0000e+00 - val_loss: 0.5225 - val_accuracy: 0.7878 - val_recall_3: 0.0000e+00\n",
      "Epoch 14/100\n",
      "165/165 [==============================] - 4s 23ms/step - loss: 0.5236 - accuracy: 0.7873 - recall_3: 0.0000e+00 - val_loss: 0.5234 - val_accuracy: 0.7868 - val_recall_3: 0.0000e+00\n",
      "Epoch 15/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.5237 - accuracy: 0.7868 - recall_3: 0.0000e+00 - val_loss: 0.5205 - val_accuracy: 0.7887 - val_recall_3: 0.0000e+00\n",
      "Epoch 16/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5189 - accuracy: 0.7892 - recall_3: 0.0000e+00 - val_loss: 0.5201 - val_accuracy: 0.7906 - val_recall_3: 0.0000e+00\n",
      "Epoch 17/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.5242 - accuracy: 0.7860 - recall_3: 0.0000e+00 - val_loss: 0.5207 - val_accuracy: 0.7889 - val_recall_3: 0.0000e+00\n",
      "Epoch 18/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.5189 - accuracy: 0.7901 - recall_3: 0.0000e+00 - val_loss: 0.5151 - val_accuracy: 0.7916 - val_recall_3: 0.0000e+00\n",
      "Epoch 19/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5179 - accuracy: 0.7894 - recall_3: 0.0000e+00 - val_loss: 0.5183 - val_accuracy: 0.7897 - val_recall_3: 0.0000e+00\n",
      "Epoch 20/100\n",
      "165/165 [==============================] - 5s 25ms/step - loss: 0.5238 - accuracy: 0.7849 - recall_3: 0.0000e+00 - val_loss: 0.5239 - val_accuracy: 0.7865 - val_recall_3: 0.0000e+00\n",
      "Epoch 21/100\n",
      "165/165 [==============================] - 5s 27ms/step - loss: 0.5178 - accuracy: 0.7903 - recall_3: 0.0000e+00 - val_loss: 0.5186 - val_accuracy: 0.7901 - val_recall_3: 0.0000e+00\n",
      "Epoch 22/100\n",
      "165/165 [==============================] - 4s 25ms/step - loss: 0.5244 - accuracy: 0.7854 - recall_3: 0.0000e+00 - val_loss: 0.5168 - val_accuracy: 0.7921 - val_recall_3: 0.0000e+00\n",
      "Epoch 23/100\n",
      "165/165 [==============================] - 5s 26ms/step - loss: 0.5135 - accuracy: 0.7926 - recall_3: 0.0000e+00 - val_loss: 0.5186 - val_accuracy: 0.7891 - val_recall_3: 0.0000e+00\n",
      "Epoch 24/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.5230 - accuracy: 0.7865 - recall_3: 0.0000e+00 - val_loss: 0.5189 - val_accuracy: 0.7897 - val_recall_3: 0.0000e+00\n",
      "Epoch 25/100\n",
      "165/165 [==============================] - 5s 26ms/step - loss: 0.5199 - accuracy: 0.7880 - recall_3: 0.0000e+00 - val_loss: 0.5156 - val_accuracy: 0.7908 - val_recall_3: 0.0000e+00\n",
      "Epoch 26/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.5158 - accuracy: 0.7922 - recall_3: 0.0000e+00 - val_loss: 0.5128 - val_accuracy: 0.7939 - val_recall_3: 0.0000e+00\n",
      "Epoch 27/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.5229 - accuracy: 0.7856 - recall_3: 0.0000e+00 - val_loss: 0.5189 - val_accuracy: 0.7878 - val_recall_3: 0.0000e+00\n",
      "Epoch 28/100\n",
      "165/165 [==============================] - 3s 18ms/step - loss: 0.5224 - accuracy: 0.7864 - recall_3: 0.0000e+00 - val_loss: 0.5180 - val_accuracy: 0.7902 - val_recall_3: 0.0000e+00\n",
      "Epoch 29/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5192 - accuracy: 0.7879 - recall_3: 0.0000e+00 - val_loss: 0.5197 - val_accuracy: 0.7874 - val_recall_3: 0.0000e+00\n",
      "Epoch 30/100\n",
      "165/165 [==============================] - 4s 22ms/step - loss: 0.5175 - accuracy: 0.7902 - recall_3: 0.0000e+00 - val_loss: 0.5258 - val_accuracy: 0.7859 - val_recall_3: 0.0000e+00\n",
      "Epoch 31/100\n",
      "165/165 [==============================] - 4s 23ms/step - loss: 0.5153 - accuracy: 0.7917 - recall_3: 0.0000e+00 - val_loss: 0.5227 - val_accuracy: 0.7860 - val_recall_3: 0.0000e+00\n",
      "Epoch 32/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5160 - accuracy: 0.7897 - recall_3: 0.0000e+00 - val_loss: 0.5229 - val_accuracy: 0.7866 - val_recall_3: 0.0000e+00\n",
      "Epoch 33/100\n",
      "165/165 [==============================] - 3s 19ms/step - loss: 0.5154 - accuracy: 0.7907 - recall_3: 0.0000e+00 - val_loss: 0.5191 - val_accuracy: 0.7882 - val_recall_3: 0.0000e+00\n",
      "Epoch 34/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5179 - accuracy: 0.7893 - recall_3: 0.0000e+00 - val_loss: 0.5212 - val_accuracy: 0.7861 - val_recall_3: 0.0000e+00\n",
      "Epoch 35/100\n",
      "165/165 [==============================] - 4s 24ms/step - loss: 0.5184 - accuracy: 0.7879 - recall_3: 0.0000e+00 - val_loss: 0.5192 - val_accuracy: 0.7887 - val_recall_3: 0.0000e+00\n",
      "Epoch 36/100\n",
      "165/165 [==============================] - 5s 25ms/step - loss: 0.5228 - accuracy: 0.7841 - recall_3: 0.0000e+00 - val_loss: 0.5192 - val_accuracy: 0.7893 - val_recall_3: 0.0000e+00\n",
      "Epoch 37/100\n",
      "165/165 [==============================] - 4s 22ms/step - loss: 0.5191 - accuracy: 0.7874 - recall_3: 0.0000e+00 - val_loss: 0.5231 - val_accuracy: 0.7853 - val_recall_3: 0.0000e+00\n",
      "Epoch 38/100\n",
      "165/165 [==============================] - 4s 23ms/step - loss: 0.5172 - accuracy: 0.7901 - recall_3: 0.0000e+00 - val_loss: 0.5215 - val_accuracy: 0.7849 - val_recall_3: 0.0000e+00\n",
      "Epoch 39/100\n",
      "165/165 [==============================] - 4s 24ms/step - loss: 0.5183 - accuracy: 0.7881 - recall_3: 0.0000e+00 - val_loss: 0.5255 - val_accuracy: 0.7833 - val_recall_3: 0.0000e+00\n",
      "Epoch 40/100\n",
      "165/165 [==============================] - 5s 28ms/step - loss: 0.5163 - accuracy: 0.7896 - recall_3: 0.0000e+00 - val_loss: 0.5220 - val_accuracy: 0.7853 - val_recall_3: 0.0000e+00\n",
      "Epoch 41/100\n",
      "165/165 [==============================] - 5s 27ms/step - loss: 0.5225 - accuracy: 0.7861 - recall_3: 0.0000e+00 - val_loss: 0.5151 - val_accuracy: 0.7895 - val_recall_3: 0.0000e+00\n",
      "Epoch 42/100\n",
      "165/165 [==============================] - 5s 28ms/step - loss: 0.5190 - accuracy: 0.7883 - recall_3: 0.0000e+00 - val_loss: 0.5161 - val_accuracy: 0.7892 - val_recall_3: 0.0000e+00\n",
      "Epoch 43/100\n",
      "165/165 [==============================] - 3s 19ms/step - loss: 0.5124 - accuracy: 0.7921 - recall_3: 0.0000e+00 - val_loss: 0.5176 - val_accuracy: 0.7873 - val_recall_3: 0.0000e+00\n",
      "Epoch 44/100\n",
      "165/165 [==============================] - 4s 19ms/step - loss: 0.5158 - accuracy: 0.7902 - recall_3: 0.0000e+00 - val_loss: 0.5222 - val_accuracy: 0.7853 - val_recall_3: 0.0000e+00\n",
      "Epoch 45/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5163 - accuracy: 0.7892 - recall_3: 0.0000e+00 - val_loss: 0.5113 - val_accuracy: 0.7929 - val_recall_3: 0.0000e+00\n",
      "Epoch 46/100\n",
      "165/165 [==============================] - 4s 19ms/step - loss: 0.5166 - accuracy: 0.7887 - recall_3: 0.0000e+00 - val_loss: 0.5114 - val_accuracy: 0.7927 - val_recall_3: 0.0000e+00\n",
      "Epoch 47/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5165 - accuracy: 0.7873 - recall_3: 0.0000e+00 - val_loss: 0.5165 - val_accuracy: 0.7870 - val_recall_3: 0.0000e+00\n",
      "Epoch 48/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.5171 - accuracy: 0.7889 - recall_3: 0.0000e+00 - val_loss: 0.5185 - val_accuracy: 0.7868 - val_recall_3: 0.0000e+00\n",
      "Epoch 49/100\n",
      "165/165 [==============================] - 5s 26ms/step - loss: 0.5234 - accuracy: 0.7833 - recall_3: 0.0000e+00 - val_loss: 0.5185 - val_accuracy: 0.7852 - val_recall_3: 0.0000e+00\n",
      "Epoch 50/100\n",
      "165/165 [==============================] - 4s 24ms/step - loss: 0.5153 - accuracy: 0.7886 - recall_3: 0.0000e+00 - val_loss: 0.5166 - val_accuracy: 0.7883 - val_recall_3: 0.0000e+00\n",
      "Epoch 51/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5171 - accuracy: 0.7877 - recall_3: 0.0000e+00 - val_loss: 0.5190 - val_accuracy: 0.7876 - val_recall_3: 0.0000e+00\n",
      "Epoch 52/100\n",
      "165/165 [==============================] - 4s 22ms/step - loss: 0.5134 - accuracy: 0.7903 - recall_3: 0.0000e+00 - val_loss: 0.5216 - val_accuracy: 0.7838 - val_recall_3: 0.0000e+00\n",
      "Epoch 53/100\n",
      "165/165 [==============================] - 5s 28ms/step - loss: 0.5086 - accuracy: 0.7934 - recall_3: 0.0000e+00 - val_loss: 0.5161 - val_accuracy: 0.7884 - val_recall_3: 0.0000e+00\n",
      "Epoch 54/100\n",
      "165/165 [==============================] - 5s 28ms/step - loss: 0.5184 - accuracy: 0.7870 - recall_3: 0.0000e+00 - val_loss: 0.5183 - val_accuracy: 0.7844 - val_recall_3: 0.0000e+00\n",
      "Epoch 55/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5133 - accuracy: 0.7896 - recall_3: 0.0000e+00 - val_loss: 0.5175 - val_accuracy: 0.7855 - val_recall_3: 0.0000e+00\n",
      "Epoch 56/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5152 - accuracy: 0.7877 - recall_3: 0.0000e+00 - val_loss: 0.5210 - val_accuracy: 0.7843 - val_recall_3: 0.0000e+00\n",
      "Epoch 57/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.5140 - accuracy: 0.7886 - recall_3: 0.0000e+00 - val_loss: 0.5206 - val_accuracy: 0.7841 - val_recall_3: 0.0000e+00\n",
      "Epoch 58/100\n",
      "165/165 [==============================] - 5s 27ms/step - loss: 0.5132 - accuracy: 0.7893 - recall_3: 0.0000e+00 - val_loss: 0.5116 - val_accuracy: 0.7895 - val_recall_3: 0.0000e+00\n",
      "Epoch 59/100\n",
      "165/165 [==============================] - 4s 25ms/step - loss: 0.5158 - accuracy: 0.7864 - recall_3: 0.0000e+00 - val_loss: 0.5101 - val_accuracy: 0.7914 - val_recall_3: 0.0000e+00\n",
      "Epoch 60/100\n",
      "165/165 [==============================] - 3s 19ms/step - loss: 0.5121 - accuracy: 0.7893 - recall_3: 0.0000e+00 - val_loss: 0.5146 - val_accuracy: 0.7866 - val_recall_3: 0.0000e+00\n",
      "Epoch 61/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.5109 - accuracy: 0.7896 - recall_3: 0.0000e+00 - val_loss: 0.5119 - val_accuracy: 0.7894 - val_recall_3: 0.0000e+00\n",
      "Epoch 62/100\n",
      "165/165 [==============================] - 4s 23ms/step - loss: 0.5153 - accuracy: 0.7872 - recall_3: 0.0000e+00 - val_loss: 0.5151 - val_accuracy: 0.7875 - val_recall_3: 0.0000e+00\n",
      "Epoch 63/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.5121 - accuracy: 0.7887 - recall_3: 0.0000e+00 - val_loss: 0.5091 - val_accuracy: 0.7912 - val_recall_3: 0.0000e+00\n",
      "Epoch 64/100\n",
      "165/165 [==============================] - 5s 27ms/step - loss: 0.5113 - accuracy: 0.7887 - recall_3: 0.0000e+00 - val_loss: 0.5173 - val_accuracy: 0.7846 - val_recall_3: 0.0000e+00\n",
      "Epoch 65/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5086 - accuracy: 0.7907 - recall_3: 0.0000e+00 - val_loss: 0.5091 - val_accuracy: 0.7884 - val_recall_3: 0.0000e+00\n",
      "Epoch 66/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.5128 - accuracy: 0.7871 - recall_3: 0.0000e+00 - val_loss: 0.5093 - val_accuracy: 0.7896 - val_recall_3: 0.0000e+00\n",
      "Epoch 67/100\n",
      "165/165 [==============================] - 5s 26ms/step - loss: 0.5127 - accuracy: 0.7861 - recall_3: 0.0000e+00 - val_loss: 0.5138 - val_accuracy: 0.7860 - val_recall_3: 0.0000e+00\n",
      "Epoch 68/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5120 - accuracy: 0.7869 - recall_3: 0.0000e+00 - val_loss: 0.5129 - val_accuracy: 0.7847 - val_recall_3: 0.0000e+00\n",
      "Epoch 69/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5107 - accuracy: 0.7871 - recall_3: 0.0000e+00 - val_loss: 0.5151 - val_accuracy: 0.7841 - val_recall_3: 0.0000e+00\n",
      "Epoch 70/100\n",
      "165/165 [==============================] - 3s 19ms/step - loss: 0.5090 - accuracy: 0.7877 - recall_3: 0.0000e+00 - val_loss: 0.5128 - val_accuracy: 0.7843 - val_recall_3: 0.0000e+00\n",
      "Epoch 71/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5089 - accuracy: 0.7872 - recall_3: 0.0000e+00 - val_loss: 0.5064 - val_accuracy: 0.7885 - val_recall_3: 0.0000e+00\n",
      "Epoch 72/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.5105 - accuracy: 0.7857 - recall_3: 0.0000e+00 - val_loss: 0.5104 - val_accuracy: 0.7858 - val_recall_3: 0.0000e+00\n",
      "Epoch 73/100\n",
      "165/165 [==============================] - 4s 23ms/step - loss: 0.5054 - accuracy: 0.7894 - recall_3: 0.0000e+00 - val_loss: 0.5066 - val_accuracy: 0.7883 - val_recall_3: 0.0000e+00\n",
      "Epoch 74/100\n",
      "165/165 [==============================] - 4s 24ms/step - loss: 0.5067 - accuracy: 0.7874 - recall_3: 0.0000e+00 - val_loss: 0.5073 - val_accuracy: 0.7868 - val_recall_3: 0.0000e+00\n",
      "Epoch 75/100\n",
      "165/165 [==============================] - 4s 25ms/step - loss: 0.5063 - accuracy: 0.7876 - recall_3: 0.0000e+00 - val_loss: 0.5071 - val_accuracy: 0.7865 - val_recall_3: 0.0000e+00\n",
      "Epoch 76/100\n",
      "165/165 [==============================] - 5s 26ms/step - loss: 0.5014 - accuracy: 0.7902 - recall_3: 0.0000e+00 - val_loss: 0.5032 - val_accuracy: 0.7900 - val_recall_3: 0.0000e+00\n",
      "Epoch 77/100\n",
      "165/165 [==============================] - 4s 22ms/step - loss: 0.5058 - accuracy: 0.7878 - recall_3: 0.0000e+00 - val_loss: 0.5083 - val_accuracy: 0.7854 - val_recall_3: 0.0000e+00\n",
      "Epoch 78/100\n",
      "165/165 [==============================] - 5s 26ms/step - loss: 0.5029 - accuracy: 0.7876 - recall_3: 0.0000e+00 - val_loss: 0.5054 - val_accuracy: 0.7865 - val_recall_3: 0.0000e+00\n",
      "Epoch 79/100\n",
      "165/165 [==============================] - 3s 19ms/step - loss: 0.5002 - accuracy: 0.7895 - recall_3: 0.0000e+00 - val_loss: 0.5066 - val_accuracy: 0.7848 - val_recall_3: 0.0000e+00\n",
      "Epoch 80/100\n",
      "165/165 [==============================] - 5s 26ms/step - loss: 0.5009 - accuracy: 0.7878 - recall_3: 0.0000e+00 - val_loss: 0.5008 - val_accuracy: 0.7891 - val_recall_3: 0.0000e+00\n",
      "Epoch 81/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5007 - accuracy: 0.7876 - recall_3: 0.0000e+00 - val_loss: 0.5010 - val_accuracy: 0.7864 - val_recall_3: 0.0000e+00\n",
      "Epoch 82/100\n",
      "165/165 [==============================] - 3s 19ms/step - loss: 0.4963 - accuracy: 0.7895 - recall_3: 0.0000e+00 - val_loss: 0.4973 - val_accuracy: 0.7887 - val_recall_3: 0.0000e+00\n",
      "Epoch 83/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.5002 - accuracy: 0.7859 - recall_3: 0.0000e+00 - val_loss: 0.4986 - val_accuracy: 0.7859 - val_recall_3: 0.0000e+00\n",
      "Epoch 84/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.4952 - accuracy: 0.7883 - recall_3: 0.0000e+00 - val_loss: 0.4974 - val_accuracy: 0.7877 - val_recall_3: 0.0000e+00\n",
      "Epoch 85/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.4955 - accuracy: 0.7885 - recall_3: 0.0000e+00 - val_loss: 0.4935 - val_accuracy: 0.7885 - val_recall_3: 0.0000e+00\n",
      "Epoch 86/100\n",
      "165/165 [==============================] - 5s 25ms/step - loss: 0.4898 - accuracy: 0.7911 - recall_3: 0.0000e+00 - val_loss: 0.4972 - val_accuracy: 0.7841 - val_recall_3: 0.0000e+00\n",
      "Epoch 87/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.4874 - accuracy: 0.7899 - recall_3: 0.0000e+00 - val_loss: 0.4960 - val_accuracy: 0.7842 - val_recall_3: 0.0000e+00\n",
      "Epoch 88/100\n",
      "165/165 [==============================] - 4s 22ms/step - loss: 0.4911 - accuracy: 0.7893 - recall_3: 0.0000e+00 - val_loss: 0.4927 - val_accuracy: 0.7878 - val_recall_3: 0.0000e+00\n",
      "Epoch 89/100\n",
      "165/165 [==============================] - 5s 27ms/step - loss: 0.4913 - accuracy: 0.7870 - recall_3: 0.0000e+00 - val_loss: 0.4899 - val_accuracy: 0.7864 - val_recall_3: 0.0000e+00\n",
      "Epoch 90/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.4853 - accuracy: 0.7911 - recall_3: 0.0000e+00 - val_loss: 0.4867 - val_accuracy: 0.7887 - val_recall_3: 0.0000e+00\n",
      "Epoch 91/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.4864 - accuracy: 0.7892 - recall_3: 0.0000e+00 - val_loss: 0.4848 - val_accuracy: 0.7916 - val_recall_3: 0.0000e+00\n",
      "Epoch 92/100\n",
      "165/165 [==============================] - 4s 23ms/step - loss: 0.4844 - accuracy: 0.7897 - recall_3: 0.0000e+00 - val_loss: 0.4886 - val_accuracy: 0.7858 - val_recall_3: 0.0000e+00\n",
      "Epoch 93/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.4830 - accuracy: 0.7888 - recall_3: 0.0000e+00 - val_loss: 0.4800 - val_accuracy: 0.7895 - val_recall_3: 0.0000e+00\n",
      "Epoch 94/100\n",
      "165/165 [==============================] - 5s 27ms/step - loss: 0.4830 - accuracy: 0.7881 - recall_3: 0.0000e+00 - val_loss: 0.4823 - val_accuracy: 0.7891 - val_recall_3: 0.0000e+00\n",
      "Epoch 95/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.4846 - accuracy: 0.7870 - recall_3: 0.0000e+00 - val_loss: 0.4800 - val_accuracy: 0.7885 - val_recall_3: 0.0000e+00\n",
      "Epoch 96/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.4766 - accuracy: 0.7885 - recall_3: 0.0000e+00 - val_loss: 0.4816 - val_accuracy: 0.7860 - val_recall_3: 0.0000e+00\n",
      "Epoch 97/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.4735 - accuracy: 0.7909 - recall_3: 0.0000e+00 - val_loss: 0.4701 - val_accuracy: 0.7925 - val_recall_3: 0.0000e+00\n",
      "Epoch 98/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.4749 - accuracy: 0.7888 - recall_3: 0.0000e+00 - val_loss: 0.4762 - val_accuracy: 0.7878 - val_recall_3: 0.0000e+00\n",
      "Epoch 99/100\n",
      "165/165 [==============================] - 4s 21ms/step - loss: 0.4740 - accuracy: 0.7888 - recall_3: 0.0000e+00 - val_loss: 0.4765 - val_accuracy: 0.7858 - val_recall_3: 0.0000e+00\n",
      "Epoch 100/100\n",
      "165/165 [==============================] - 4s 20ms/step - loss: 0.4714 - accuracy: 0.7891 - recall_3: 0.0000e+00 - val_loss: 0.4733 - val_accuracy: 0.7882 - val_recall_3: 0.0000e+00\n",
      "Model training finished.\n",
      "Evaluating model performance...\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.4683 - accuracy: 0.7919 - recall_3: 0.0000e+00\n",
      "Test Accuracy: 79.19%\n",
      "Test Recall: 0.00%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "train_sample_size = int(train_size * 0.3)\n",
    "small_train_dataset = train_dataset.unbatch().take(train_sample_size).batch(batch_size)\n",
    "\n",
    "bnn_model_small = create_bnn_model(train_sample_size)\n",
    "run_experiment(bnn_model_small, bce_loss, small_train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdc983b-de13-4601-8928-1fc509a63a87",
   "metadata": {},
   "source": [
    "Since we have trained a BNN model, the model produces a different output each time we call it with the same input, since each time a new set of weights are sampled from the distributions to construct the network and produce an output. The less certain the mode weights are, the more variability (wider range) we will see in the outputs of the same inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02b7378c-cfcb-4879-9770-d1ba67159103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions mean: 0.19, min: 0.12, max: 0.3, range: 0.18 - Actual: 0.0\n",
      "Predictions mean: 0.18, min: 0.11, max: 0.27, range: 0.16 - Actual: 0.0\n",
      "Predictions mean: 0.18, min: 0.12, max: 0.3, range: 0.18 - Actual: 0.0\n",
      "Predictions mean: 0.16, min: 0.11, max: 0.25, range: 0.13 - Actual: 0.0\n",
      "Predictions mean: 0.27, min: 0.18, max: 0.38, range: 0.2 - Actual: 0.0\n",
      "Predictions mean: 0.2, min: 0.13, max: 0.33, range: 0.2 - Actual: 0.0\n",
      "Predictions mean: 0.17, min: 0.11, max: 0.25, range: 0.14 - Actual: 0.0\n",
      "Predictions mean: 0.17, min: 0.12, max: 0.27, range: 0.16 - Actual: 0.0\n",
      "Predictions mean: 0.14, min: 0.11, max: 0.18, range: 0.07 - Actual: 0.0\n",
      "Predictions mean: 0.27, min: 0.16, max: 0.37, range: 0.21 - Actual: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_predictions(model, iterations=100):\n",
    "    predicted = []\n",
    "    for _ in range(iterations):\n",
    "        predicted.append(model(examples).numpy())\n",
    "    predicted = np.concatenate(predicted, axis=1)\n",
    "\n",
    "    prediction_mean = np.mean(predicted, axis=1).tolist()\n",
    "    prediction_min = np.min(predicted, axis=1).tolist()\n",
    "    prediction_max = np.max(predicted, axis=1).tolist()\n",
    "    prediction_range = (np.max(predicted, axis=1) - np.min(predicted, axis=1)).tolist()\n",
    "\n",
    "    for idx in range(sample):\n",
    "        print(\n",
    "            f\"Predictions mean: {round(prediction_mean[idx], 2)}, \"\n",
    "            f\"min: {round(prediction_min[idx], 2)}, \"\n",
    "            f\"max: {round(prediction_max[idx], 2)}, \"\n",
    "            f\"range: {round(prediction_range[idx], 2)} - \"\n",
    "            f\"Actual: {targets[idx]}\"\n",
    "        )\n",
    "\n",
    "\n",
    "compute_predictions(bnn_model_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45d9a4b-c72d-4a4e-ba65-4cadb6f3b89f",
   "metadata": {},
   "source": [
    "### Train BNN with the whole training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbe98d3a-f28f-4f4b-9ca7-1d8a8b90002f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/100\n",
      "548/548 [==============================] - 9s 13ms/step - loss: 0.4578 - accuracy: 0.2116 - recall_4: 0.9999 - val_loss: 0.4324 - val_accuracy: 0.2103 - val_recall_4: 1.0000\n",
      "Epoch 2/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3865 - accuracy: 0.2215 - recall_4: 0.9838 - val_loss: 0.3404 - val_accuracy: 0.2411 - val_recall_4: 0.9534\n",
      "Epoch 3/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.3087 - accuracy: 0.3106 - recall_4: 0.8408 - val_loss: 0.2749 - val_accuracy: 0.4361 - val_recall_4: 0.6420\n",
      "Epoch 4/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.2523 - accuracy: 0.5283 - recall_4: 0.4669 - val_loss: 0.2182 - val_accuracy: 0.7129 - val_recall_4: 0.1612\n",
      "Epoch 5/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.2086 - accuracy: 0.7364 - recall_4: 0.0995 - val_loss: 0.1912 - val_accuracy: 0.7877 - val_recall_4: 0.0146\n",
      "Epoch 6/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1839 - accuracy: 0.7856 - recall_4: 0.0081 - val_loss: 0.1755 - val_accuracy: 0.7832 - val_recall_4: 5.6285e-04\n",
      "Epoch 7/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1708 - accuracy: 0.7882 - recall_4: 6.7338e-05 - val_loss: 0.1684 - val_accuracy: 0.7883 - val_recall_4: 0.0000e+00\n",
      "Epoch 8/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1664 - accuracy: 0.7880 - recall_4: 0.0000e+00 - val_loss: 0.1665 - val_accuracy: 0.7843 - val_recall_4: 0.0000e+00\n",
      "Epoch 9/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1648 - accuracy: 0.7878 - recall_4: 0.0000e+00 - val_loss: 0.1621 - val_accuracy: 0.7925 - val_recall_4: 0.0000e+00\n",
      "Epoch 10/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1636 - accuracy: 0.7877 - recall_4: 0.0000e+00 - val_loss: 0.1630 - val_accuracy: 0.7881 - val_recall_4: 0.0000e+00\n",
      "Epoch 11/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1625 - accuracy: 0.7882 - recall_4: 0.0000e+00 - val_loss: 0.1610 - val_accuracy: 0.7894 - val_recall_4: 0.0000e+00\n",
      "Epoch 12/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1613 - accuracy: 0.7881 - recall_4: 0.0000e+00 - val_loss: 0.1602 - val_accuracy: 0.7891 - val_recall_4: 0.0000e+00\n",
      "Epoch 13/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1591 - accuracy: 0.7892 - recall_4: 0.0000e+00 - val_loss: 0.1606 - val_accuracy: 0.7853 - val_recall_4: 0.0000e+00\n",
      "Epoch 14/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1575 - accuracy: 0.7888 - recall_4: 3.3753e-05 - val_loss: 0.1573 - val_accuracy: 0.7894 - val_recall_4: 0.0000e+00\n",
      "Epoch 15/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1556 - accuracy: 0.7890 - recall_4: 5.7421e-04 - val_loss: 0.1570 - val_accuracy: 0.7846 - val_recall_4: 1.8748e-04\n",
      "Epoch 16/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1533 - accuracy: 0.7894 - recall_4: 0.0013 - val_loss: 0.1544 - val_accuracy: 0.7869 - val_recall_4: 0.0017\n",
      "Epoch 17/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1519 - accuracy: 0.7890 - recall_4: 0.0017 - val_loss: 0.1498 - val_accuracy: 0.7913 - val_recall_4: 0.0042\n",
      "Epoch 18/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.1491 - accuracy: 0.7901 - recall_4: 0.0103 - val_loss: 0.1486 - val_accuracy: 0.7915 - val_recall_4: 0.0246\n",
      "Epoch 19/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.1470 - accuracy: 0.7910 - recall_4: 0.0252 - val_loss: 0.1473 - val_accuracy: 0.7893 - val_recall_4: 0.0288\n",
      "Epoch 20/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1439 - accuracy: 0.7947 - recall_4: 0.0507 - val_loss: 0.1429 - val_accuracy: 0.7943 - val_recall_4: 0.0583\n",
      "Epoch 21/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.1418 - accuracy: 0.7971 - recall_4: 0.0709 - val_loss: 0.1376 - val_accuracy: 0.8050 - val_recall_4: 0.1008\n",
      "Epoch 22/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1385 - accuracy: 0.8037 - recall_4: 0.1133 - val_loss: 0.1376 - val_accuracy: 0.8066 - val_recall_4: 0.1282\n",
      "Epoch 23/100\n",
      "548/548 [==============================] - 6s 9ms/step - loss: 0.1365 - accuracy: 0.8091 - recall_4: 0.1609 - val_loss: 0.1358 - val_accuracy: 0.8112 - val_recall_4: 0.1770\n",
      "Epoch 24/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.1342 - accuracy: 0.8147 - recall_4: 0.2142 - val_loss: 0.1336 - val_accuracy: 0.8137 - val_recall_4: 0.1954\n",
      "Epoch 25/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.1323 - accuracy: 0.8180 - recall_4: 0.2433 - val_loss: 0.1319 - val_accuracy: 0.8195 - val_recall_4: 0.2580\n",
      "Epoch 26/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1304 - accuracy: 0.8218 - recall_4: 0.2828 - val_loss: 0.1305 - val_accuracy: 0.8219 - val_recall_4: 0.2910\n",
      "Epoch 27/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1289 - accuracy: 0.8244 - recall_4: 0.3132 - val_loss: 0.1286 - val_accuracy: 0.8275 - val_recall_4: 0.3437\n",
      "Epoch 28/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1283 - accuracy: 0.8262 - recall_4: 0.3356 - val_loss: 0.1283 - val_accuracy: 0.8272 - val_recall_4: 0.3440\n",
      "Epoch 29/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1272 - accuracy: 0.8282 - recall_4: 0.3593 - val_loss: 0.1269 - val_accuracy: 0.8279 - val_recall_4: 0.3762\n",
      "Epoch 30/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1262 - accuracy: 0.8295 - recall_4: 0.3750 - val_loss: 0.1257 - val_accuracy: 0.8313 - val_recall_4: 0.3912\n",
      "Epoch 31/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.1258 - accuracy: 0.8306 - recall_4: 0.3909 - val_loss: 0.1260 - val_accuracy: 0.8316 - val_recall_4: 0.3948\n",
      "Epoch 32/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1241 - accuracy: 0.8328 - recall_4: 0.3989 - val_loss: 0.1247 - val_accuracy: 0.8289 - val_recall_4: 0.4159\n",
      "Epoch 33/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1244 - accuracy: 0.8325 - recall_4: 0.4098 - val_loss: 0.1229 - val_accuracy: 0.8352 - val_recall_4: 0.4193\n",
      "Epoch 34/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1240 - accuracy: 0.8334 - recall_4: 0.4178 - val_loss: 0.1236 - val_accuracy: 0.8330 - val_recall_4: 0.4123\n",
      "Epoch 35/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1235 - accuracy: 0.8329 - recall_4: 0.4148 - val_loss: 0.1220 - val_accuracy: 0.8350 - val_recall_4: 0.4216\n",
      "Epoch 36/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1237 - accuracy: 0.8332 - recall_4: 0.4188 - val_loss: 0.1245 - val_accuracy: 0.8347 - val_recall_4: 0.4065\n",
      "Epoch 37/100\n",
      "548/548 [==============================] - 5s 8ms/step - loss: 0.1228 - accuracy: 0.8348 - recall_4: 0.4290 - val_loss: 0.1216 - val_accuracy: 0.8343 - val_recall_4: 0.4109\n",
      "Epoch 38/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.1232 - accuracy: 0.8345 - recall_4: 0.4284 - val_loss: 0.1230 - val_accuracy: 0.8373 - val_recall_4: 0.4405\n",
      "Epoch 39/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1232 - accuracy: 0.8345 - recall_4: 0.4316 - val_loss: 0.1211 - val_accuracy: 0.8383 - val_recall_4: 0.4296\n",
      "Epoch 40/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1222 - accuracy: 0.8360 - recall_4: 0.4339 - val_loss: 0.1235 - val_accuracy: 0.8343 - val_recall_4: 0.4306\n",
      "Epoch 41/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1220 - accuracy: 0.8368 - recall_4: 0.4346 - val_loss: 0.1213 - val_accuracy: 0.8349 - val_recall_4: 0.4360\n",
      "Epoch 42/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1220 - accuracy: 0.8364 - recall_4: 0.4364 - val_loss: 0.1230 - val_accuracy: 0.8352 - val_recall_4: 0.4346\n",
      "Epoch 43/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.1215 - accuracy: 0.8363 - recall_4: 0.4372 - val_loss: 0.1212 - val_accuracy: 0.8379 - val_recall_4: 0.4480\n",
      "Epoch 44/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1214 - accuracy: 0.8370 - recall_4: 0.4358 - val_loss: 0.1232 - val_accuracy: 0.8324 - val_recall_4: 0.4301\n",
      "Epoch 45/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1214 - accuracy: 0.8377 - recall_4: 0.4416 - val_loss: 0.1235 - val_accuracy: 0.8344 - val_recall_4: 0.4336\n",
      "Epoch 46/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1214 - accuracy: 0.8377 - recall_4: 0.4376 - val_loss: 0.1203 - val_accuracy: 0.8388 - val_recall_4: 0.4368\n",
      "Epoch 47/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1213 - accuracy: 0.8373 - recall_4: 0.4382 - val_loss: 0.1212 - val_accuracy: 0.8395 - val_recall_4: 0.4424\n",
      "Epoch 48/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1210 - accuracy: 0.8384 - recall_4: 0.4402 - val_loss: 0.1195 - val_accuracy: 0.8410 - val_recall_4: 0.4439\n",
      "Epoch 49/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1205 - accuracy: 0.8390 - recall_4: 0.4432 - val_loss: 0.1220 - val_accuracy: 0.8375 - val_recall_4: 0.4351\n",
      "Epoch 50/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1210 - accuracy: 0.8379 - recall_4: 0.4410 - val_loss: 0.1211 - val_accuracy: 0.8375 - val_recall_4: 0.4422\n",
      "Epoch 51/100\n",
      "548/548 [==============================] - 6s 9ms/step - loss: 0.1203 - accuracy: 0.8392 - recall_4: 0.4405 - val_loss: 0.1199 - val_accuracy: 0.8411 - val_recall_4: 0.4353\n",
      "Epoch 52/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1205 - accuracy: 0.8396 - recall_4: 0.4445 - val_loss: 0.1210 - val_accuracy: 0.8379 - val_recall_4: 0.4469\n",
      "Epoch 53/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1207 - accuracy: 0.8392 - recall_4: 0.4427 - val_loss: 0.1194 - val_accuracy: 0.8419 - val_recall_4: 0.4598\n",
      "Epoch 54/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1201 - accuracy: 0.8398 - recall_4: 0.4459 - val_loss: 0.1201 - val_accuracy: 0.8397 - val_recall_4: 0.4357\n",
      "Epoch 55/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1203 - accuracy: 0.8389 - recall_4: 0.4420 - val_loss: 0.1206 - val_accuracy: 0.8379 - val_recall_4: 0.4377\n",
      "Epoch 56/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.1201 - accuracy: 0.8397 - recall_4: 0.4465 - val_loss: 0.1190 - val_accuracy: 0.8399 - val_recall_4: 0.4503\n",
      "Epoch 57/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1201 - accuracy: 0.8396 - recall_4: 0.4434 - val_loss: 0.1198 - val_accuracy: 0.8398 - val_recall_4: 0.4442\n",
      "Epoch 58/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1197 - accuracy: 0.8405 - recall_4: 0.4467 - val_loss: 0.1186 - val_accuracy: 0.8423 - val_recall_4: 0.4565\n",
      "Epoch 59/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1200 - accuracy: 0.8402 - recall_4: 0.4453 - val_loss: 0.1190 - val_accuracy: 0.8420 - val_recall_4: 0.4449\n",
      "Epoch 60/100\n",
      "548/548 [==============================] - 8s 13ms/step - loss: 0.1201 - accuracy: 0.8394 - recall_4: 0.4461 - val_loss: 0.1187 - val_accuracy: 0.8409 - val_recall_4: 0.4441\n",
      "Epoch 61/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1203 - accuracy: 0.8399 - recall_4: 0.4483 - val_loss: 0.1195 - val_accuracy: 0.8408 - val_recall_4: 0.4523\n",
      "Epoch 62/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1197 - accuracy: 0.8401 - recall_4: 0.4497 - val_loss: 0.1197 - val_accuracy: 0.8408 - val_recall_4: 0.4441\n",
      "Epoch 63/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1201 - accuracy: 0.8395 - recall_4: 0.4422 - val_loss: 0.1203 - val_accuracy: 0.8394 - val_recall_4: 0.4415\n",
      "Epoch 64/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1200 - accuracy: 0.8403 - recall_4: 0.4445 - val_loss: 0.1218 - val_accuracy: 0.8380 - val_recall_4: 0.4528\n",
      "Epoch 65/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1195 - accuracy: 0.8411 - recall_4: 0.4444 - val_loss: 0.1194 - val_accuracy: 0.8427 - val_recall_4: 0.4633\n",
      "Epoch 66/100\n",
      "548/548 [==============================] - 6s 9ms/step - loss: 0.1194 - accuracy: 0.8414 - recall_4: 0.4458 - val_loss: 0.1179 - val_accuracy: 0.8430 - val_recall_4: 0.4502\n",
      "Epoch 67/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1191 - accuracy: 0.8406 - recall_4: 0.4481 - val_loss: 0.1224 - val_accuracy: 0.8380 - val_recall_4: 0.4459\n",
      "Epoch 68/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.1199 - accuracy: 0.8402 - recall_4: 0.4460 - val_loss: 0.1203 - val_accuracy: 0.8390 - val_recall_4: 0.4411\n",
      "Epoch 69/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1194 - accuracy: 0.8410 - recall_4: 0.4495 - val_loss: 0.1184 - val_accuracy: 0.8428 - val_recall_4: 0.4489\n",
      "Epoch 70/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.1196 - accuracy: 0.8411 - recall_4: 0.4441 - val_loss: 0.1182 - val_accuracy: 0.8444 - val_recall_4: 0.4376\n",
      "Epoch 71/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.1193 - accuracy: 0.8414 - recall_4: 0.4466 - val_loss: 0.1190 - val_accuracy: 0.8429 - val_recall_4: 0.4622\n",
      "Epoch 72/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.1195 - accuracy: 0.8416 - recall_4: 0.4442 - val_loss: 0.1197 - val_accuracy: 0.8404 - val_recall_4: 0.4399\n",
      "Epoch 73/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1191 - accuracy: 0.8411 - recall_4: 0.4456 - val_loss: 0.1204 - val_accuracy: 0.8391 - val_recall_4: 0.4416\n",
      "Epoch 74/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.1191 - accuracy: 0.8410 - recall_4: 0.4474 - val_loss: 0.1175 - val_accuracy: 0.8434 - val_recall_4: 0.4402\n",
      "Epoch 75/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1195 - accuracy: 0.8407 - recall_4: 0.4490 - val_loss: 0.1181 - val_accuracy: 0.8417 - val_recall_4: 0.4488\n",
      "Epoch 76/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1192 - accuracy: 0.8411 - recall_4: 0.4454 - val_loss: 0.1208 - val_accuracy: 0.8378 - val_recall_4: 0.4408\n",
      "Epoch 77/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.1189 - accuracy: 0.8421 - recall_4: 0.4509 - val_loss: 0.1199 - val_accuracy: 0.8423 - val_recall_4: 0.4437\n",
      "Epoch 78/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1189 - accuracy: 0.8415 - recall_4: 0.4487 - val_loss: 0.1187 - val_accuracy: 0.8423 - val_recall_4: 0.4437\n",
      "Epoch 79/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.1192 - accuracy: 0.8410 - recall_4: 0.4444 - val_loss: 0.1185 - val_accuracy: 0.8422 - val_recall_4: 0.4552\n",
      "Epoch 80/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1191 - accuracy: 0.8411 - recall_4: 0.4475 - val_loss: 0.1191 - val_accuracy: 0.8422 - val_recall_4: 0.4529\n",
      "Epoch 81/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1188 - accuracy: 0.8418 - recall_4: 0.4488 - val_loss: 0.1181 - val_accuracy: 0.8452 - val_recall_4: 0.4419\n",
      "Epoch 82/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1189 - accuracy: 0.8419 - recall_4: 0.4457 - val_loss: 0.1179 - val_accuracy: 0.8450 - val_recall_4: 0.4544\n",
      "Epoch 83/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1189 - accuracy: 0.8421 - recall_4: 0.4504 - val_loss: 0.1200 - val_accuracy: 0.8410 - val_recall_4: 0.4506\n",
      "Epoch 84/100\n",
      "548/548 [==============================] - 6s 9ms/step - loss: 0.1189 - accuracy: 0.8420 - recall_4: 0.4477 - val_loss: 0.1184 - val_accuracy: 0.8423 - val_recall_4: 0.4492\n",
      "Epoch 85/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1189 - accuracy: 0.8417 - recall_4: 0.4421 - val_loss: 0.1169 - val_accuracy: 0.8453 - val_recall_4: 0.4579\n",
      "Epoch 86/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.1188 - accuracy: 0.8418 - recall_4: 0.4511 - val_loss: 0.1192 - val_accuracy: 0.8407 - val_recall_4: 0.4478\n",
      "Epoch 87/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1188 - accuracy: 0.8422 - recall_4: 0.4479 - val_loss: 0.1176 - val_accuracy: 0.8447 - val_recall_4: 0.4473\n",
      "Epoch 88/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.1188 - accuracy: 0.8421 - recall_4: 0.4479 - val_loss: 0.1196 - val_accuracy: 0.8412 - val_recall_4: 0.4406\n",
      "Epoch 89/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1188 - accuracy: 0.8417 - recall_4: 0.4508 - val_loss: 0.1165 - val_accuracy: 0.8454 - val_recall_4: 0.4467\n",
      "Epoch 90/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1186 - accuracy: 0.8420 - recall_4: 0.4465 - val_loss: 0.1195 - val_accuracy: 0.8408 - val_recall_4: 0.4546\n",
      "Epoch 91/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1185 - accuracy: 0.8426 - recall_4: 0.4517 - val_loss: 0.1207 - val_accuracy: 0.8387 - val_recall_4: 0.4331\n",
      "Epoch 92/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1192 - accuracy: 0.8413 - recall_4: 0.4446 - val_loss: 0.1158 - val_accuracy: 0.8474 - val_recall_4: 0.4708\n",
      "Epoch 93/100\n",
      "548/548 [==============================] - 8s 15ms/step - loss: 0.1186 - accuracy: 0.8423 - recall_4: 0.4508 - val_loss: 0.1182 - val_accuracy: 0.8418 - val_recall_4: 0.4491\n",
      "Epoch 94/100\n",
      "548/548 [==============================] - 8s 15ms/step - loss: 0.1189 - accuracy: 0.8418 - recall_4: 0.4469 - val_loss: 0.1174 - val_accuracy: 0.8456 - val_recall_4: 0.4670\n",
      "Epoch 95/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1188 - accuracy: 0.8414 - recall_4: 0.4436 - val_loss: 0.1176 - val_accuracy: 0.8436 - val_recall_4: 0.4526\n",
      "Epoch 96/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.1187 - accuracy: 0.8425 - recall_4: 0.4455 - val_loss: 0.1181 - val_accuracy: 0.8423 - val_recall_4: 0.4552\n",
      "Epoch 97/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.1188 - accuracy: 0.8417 - recall_4: 0.4470 - val_loss: 0.1193 - val_accuracy: 0.8403 - val_recall_4: 0.4314\n",
      "Epoch 98/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.1191 - accuracy: 0.8410 - recall_4: 0.4422 - val_loss: 0.1177 - val_accuracy: 0.8448 - val_recall_4: 0.4512\n",
      "Epoch 99/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.1186 - accuracy: 0.8424 - recall_4: 0.4472 - val_loss: 0.1191 - val_accuracy: 0.8409 - val_recall_4: 0.4386\n",
      "Epoch 100/100\n",
      "548/548 [==============================] - 8s 13ms/step - loss: 0.1188 - accuracy: 0.8423 - recall_4: 0.4493 - val_loss: 0.1168 - val_accuracy: 0.8453 - val_recall_4: 0.4578\n",
      "Model training finished.\n",
      "Evaluating model performance...\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 0.1193 - accuracy: 0.8434 - recall_4: 0.4536\n",
      "Test Accuracy: 84.34%\n",
      "Test Recall: 45.36%\n",
      "Predictions mean: 0.07, min: 0.06, max: 0.1, range: 0.04 - Actual: 0.0\n",
      "Predictions mean: 0.14, min: 0.09, max: 0.32, range: 0.23 - Actual: 0.0\n",
      "Predictions mean: 0.15, min: 0.1, max: 0.26, range: 0.16 - Actual: 0.0\n",
      "Predictions mean: 0.08, min: 0.06, max: 0.12, range: 0.05 - Actual: 0.0\n",
      "Predictions mean: 0.28, min: 0.16, max: 0.46, range: 0.3 - Actual: 0.0\n",
      "Predictions mean: 0.22, min: 0.11, max: 0.41, range: 0.3 - Actual: 0.0\n",
      "Predictions mean: 0.15, min: 0.09, max: 0.33, range: 0.24 - Actual: 0.0\n",
      "Predictions mean: 0.07, min: 0.06, max: 0.11, range: 0.05 - Actual: 0.0\n",
      "Predictions mean: 0.07, min: 0.06, max: 0.09, range: 0.03 - Actual: 0.0\n",
      "Predictions mean: 0.44, min: 0.23, max: 0.66, range: 0.43 - Actual: 1.0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "bnn_model_full = create_bnn_model(train_size)\n",
    "run_experiment(bnn_model_full, mse_loss, train_dataset, test_dataset)\n",
    "\n",
    "compute_predictions(bnn_model_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91822b-c541-4db1-a86c-cd1063cd8e4c",
   "metadata": {},
   "source": [
    "## Experiment 3: probabilistic Bayesian neural network\n",
    "So far, the output of the standard and the Bayesian NN models that we built is deterministic, that is, produces a point estimate as a prediction for a given example. We can create a probabilistic NN by letting the model output a distribution. In this case, the model captures the aleatoric uncertainty as well, which is due to irreducible noise in the data, or to the stochastic nature of the process generating the data.\n",
    "\n",
    "In this example, we model the output as a IndependentNormal distribution, with learnable mean and variance parameters. If the task was classification, we would have used IndependentBernoulli with binary classes, and OneHotCategorical with multiple classes, to model distribution of the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "966e2afb-2e55-4fd4-889e-fe9ba8cf6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_probablistic_bnn_model(train_size):\n",
    "    inputs = create_model_inputs()\n",
    "    features = keras.layers.concatenate(list(inputs.values()))\n",
    "    features = layers.BatchNormalization()(features)\n",
    "\n",
    "    # Create hidden layers with weight uncertainty using the DenseVariational layer.\n",
    "    for units in hidden_units:\n",
    "        features = tfp.layers.DenseVariational(\n",
    "            units=units,\n",
    "            make_prior_fn=prior,\n",
    "            make_posterior_fn=posterior,\n",
    "            kl_weight=1 / train_size,\n",
    "            activation=\"sigmoid\",\n",
    "        )(features)\n",
    "\n",
    "    # Create a probabilisticå output (Normal distribution), and use the `Dense` layer\n",
    "    # to produce the parameters of the distribution.\n",
    "    # We set units=2 to learn both the mean and the variance of the Normal distribution.\n",
    "    ##############################\n",
    "    #Since we're modeling a binary target, the probabilistic output should be a Bernoulli distribution, not a Normal one.\n",
    "    logits = layers.Dense(units=1)(features)\n",
    "    outputs = tfp.layers.DistributionLambda(lambda t: tfp.distributions.Bernoulli(logits=t))(logits)\n",
    "\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab88e354-2ed1-446a-9f09-0fef11635235",
   "metadata": {},
   "source": [
    "Since the output of the model is a distribution, rather than a point estimate, we use the negative loglikelihood as our loss function to compute how likely to see the true data (targets) from the estimated distribution produced by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "661951f7-bd91-474f-9aaa-499dd0737c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/100\n",
      "548/548 [==============================] - 9s 12ms/step - loss: 0.6794 - accuracy: 0.5141 - recall_5: 0.4732 - val_loss: 0.6310 - val_accuracy: 0.5404 - val_recall_5: 0.4239\n",
      "Epoch 2/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.5946 - accuracy: 0.5665 - recall_5: 0.3828 - val_loss: 0.5589 - val_accuracy: 0.5979 - val_recall_5: 0.3357\n",
      "Epoch 3/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.5458 - accuracy: 0.6130 - recall_5: 0.3026 - val_loss: 0.5285 - val_accuracy: 0.6346 - val_recall_5: 0.2691\n",
      "Epoch 4/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.5245 - accuracy: 0.6469 - recall_5: 0.2516 - val_loss: 0.5212 - val_accuracy: 0.6509 - val_recall_5: 0.2384\n",
      "Epoch 5/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.5214 - accuracy: 0.6629 - recall_5: 0.2263 - val_loss: 0.5166 - val_accuracy: 0.6669 - val_recall_5: 0.2103\n",
      "Epoch 6/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.5182 - accuracy: 0.6648 - recall_5: 0.2160 - val_loss: 0.5188 - val_accuracy: 0.6621 - val_recall_5: 0.2114\n",
      "Epoch 7/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.5157 - accuracy: 0.6686 - recall_5: 0.2141 - val_loss: 0.5080 - val_accuracy: 0.6669 - val_recall_5: 0.2031\n",
      "Epoch 8/100\n",
      "548/548 [==============================] - 8s 13ms/step - loss: 0.5140 - accuracy: 0.6703 - recall_5: 0.2192 - val_loss: 0.5154 - val_accuracy: 0.6723 - val_recall_5: 0.2171\n",
      "Epoch 9/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.5141 - accuracy: 0.6701 - recall_5: 0.2155 - val_loss: 0.5140 - val_accuracy: 0.6626 - val_recall_5: 0.2206\n",
      "Epoch 10/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.5113 - accuracy: 0.6694 - recall_5: 0.2189 - val_loss: 0.5115 - val_accuracy: 0.6646 - val_recall_5: 0.2216\n",
      "Epoch 11/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.5074 - accuracy: 0.6725 - recall_5: 0.2169 - val_loss: 0.5053 - val_accuracy: 0.6770 - val_recall_5: 0.2229\n",
      "Epoch 12/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.5052 - accuracy: 0.6716 - recall_5: 0.2208 - val_loss: 0.5087 - val_accuracy: 0.6719 - val_recall_5: 0.2195\n",
      "Epoch 13/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.5024 - accuracy: 0.6750 - recall_5: 0.2212 - val_loss: 0.5008 - val_accuracy: 0.6781 - val_recall_5: 0.2244\n",
      "Epoch 14/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.4980 - accuracy: 0.6766 - recall_5: 0.2281 - val_loss: 0.5009 - val_accuracy: 0.6787 - val_recall_5: 0.2208\n",
      "Epoch 15/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.4931 - accuracy: 0.6815 - recall_5: 0.2295 - val_loss: 0.4863 - val_accuracy: 0.6831 - val_recall_5: 0.2225\n",
      "Epoch 16/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.4894 - accuracy: 0.6828 - recall_5: 0.2358 - val_loss: 0.4886 - val_accuracy: 0.6814 - val_recall_5: 0.2331\n",
      "Epoch 17/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.4829 - accuracy: 0.6830 - recall_5: 0.2444 - val_loss: 0.4864 - val_accuracy: 0.6872 - val_recall_5: 0.2431\n",
      "Epoch 18/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.4765 - accuracy: 0.6852 - recall_5: 0.2460 - val_loss: 0.4755 - val_accuracy: 0.6886 - val_recall_5: 0.2541\n",
      "Epoch 19/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.4684 - accuracy: 0.6931 - recall_5: 0.2540 - val_loss: 0.4630 - val_accuracy: 0.6904 - val_recall_5: 0.2659\n",
      "Epoch 20/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.4641 - accuracy: 0.6950 - recall_5: 0.2629 - val_loss: 0.4599 - val_accuracy: 0.6946 - val_recall_5: 0.2902\n",
      "Epoch 21/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.4562 - accuracy: 0.6966 - recall_5: 0.2746 - val_loss: 0.4490 - val_accuracy: 0.6998 - val_recall_5: 0.2900\n",
      "Epoch 22/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.4498 - accuracy: 0.7033 - recall_5: 0.2811 - val_loss: 0.4481 - val_accuracy: 0.6989 - val_recall_5: 0.2941\n",
      "Epoch 23/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.4421 - accuracy: 0.7058 - recall_5: 0.2926 - val_loss: 0.4359 - val_accuracy: 0.7087 - val_recall_5: 0.3039\n",
      "Epoch 24/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.4346 - accuracy: 0.7117 - recall_5: 0.3087 - val_loss: 0.4307 - val_accuracy: 0.7111 - val_recall_5: 0.3133\n",
      "Epoch 25/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.4278 - accuracy: 0.7165 - recall_5: 0.3176 - val_loss: 0.4241 - val_accuracy: 0.7168 - val_recall_5: 0.3344\n",
      "Epoch 26/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.4231 - accuracy: 0.7204 - recall_5: 0.3323 - val_loss: 0.4246 - val_accuracy: 0.7197 - val_recall_5: 0.3235\n",
      "Epoch 27/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.4171 - accuracy: 0.7255 - recall_5: 0.3405 - val_loss: 0.4134 - val_accuracy: 0.7299 - val_recall_5: 0.3562\n",
      "Epoch 28/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.4136 - accuracy: 0.7292 - recall_5: 0.3519 - val_loss: 0.4098 - val_accuracy: 0.7302 - val_recall_5: 0.3661\n",
      "Epoch 29/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.4071 - accuracy: 0.7343 - recall_5: 0.3666 - val_loss: 0.4077 - val_accuracy: 0.7336 - val_recall_5: 0.3663\n",
      "Epoch 30/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.4070 - accuracy: 0.7364 - recall_5: 0.3714 - val_loss: 0.4094 - val_accuracy: 0.7336 - val_recall_5: 0.3668\n",
      "Epoch 31/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.4026 - accuracy: 0.7415 - recall_5: 0.3808 - val_loss: 0.4042 - val_accuracy: 0.7372 - val_recall_5: 0.3840\n",
      "Epoch 32/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.4025 - accuracy: 0.7433 - recall_5: 0.3845 - val_loss: 0.3946 - val_accuracy: 0.7456 - val_recall_5: 0.3978\n",
      "Epoch 33/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.4000 - accuracy: 0.7446 - recall_5: 0.3917 - val_loss: 0.3951 - val_accuracy: 0.7506 - val_recall_5: 0.3935\n",
      "Epoch 34/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3986 - accuracy: 0.7456 - recall_5: 0.3954 - val_loss: 0.4009 - val_accuracy: 0.7434 - val_recall_5: 0.3977\n",
      "Epoch 35/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3987 - accuracy: 0.7465 - recall_5: 0.4036 - val_loss: 0.4026 - val_accuracy: 0.7498 - val_recall_5: 0.4044\n",
      "Epoch 36/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.3973 - accuracy: 0.7501 - recall_5: 0.4035 - val_loss: 0.3983 - val_accuracy: 0.7473 - val_recall_5: 0.4098\n",
      "Epoch 37/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.3943 - accuracy: 0.7523 - recall_5: 0.4085 - val_loss: 0.3937 - val_accuracy: 0.7569 - val_recall_5: 0.4090\n",
      "Epoch 38/100\n",
      "548/548 [==============================] - 5s 10ms/step - loss: 0.3954 - accuracy: 0.7512 - recall_5: 0.4114 - val_loss: 0.3934 - val_accuracy: 0.7572 - val_recall_5: 0.4086\n",
      "Epoch 39/100\n",
      "548/548 [==============================] - 6s 9ms/step - loss: 0.3941 - accuracy: 0.7515 - recall_5: 0.4064 - val_loss: 0.3946 - val_accuracy: 0.7542 - val_recall_5: 0.4111\n",
      "Epoch 40/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.3948 - accuracy: 0.7533 - recall_5: 0.4122 - val_loss: 0.3894 - val_accuracy: 0.7602 - val_recall_5: 0.4210\n",
      "Epoch 41/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3943 - accuracy: 0.7548 - recall_5: 0.4115 - val_loss: 0.3929 - val_accuracy: 0.7542 - val_recall_5: 0.4193\n",
      "Epoch 42/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3931 - accuracy: 0.7542 - recall_5: 0.4166 - val_loss: 0.3883 - val_accuracy: 0.7534 - val_recall_5: 0.4249\n",
      "Epoch 43/100\n",
      "548/548 [==============================] - 6s 9ms/step - loss: 0.3948 - accuracy: 0.7555 - recall_5: 0.4174 - val_loss: 0.3924 - val_accuracy: 0.7557 - val_recall_5: 0.4206\n",
      "Epoch 44/100\n",
      "548/548 [==============================] - 6s 9ms/step - loss: 0.3928 - accuracy: 0.7547 - recall_5: 0.4195 - val_loss: 0.3960 - val_accuracy: 0.7580 - val_recall_5: 0.4177\n",
      "Epoch 45/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3928 - accuracy: 0.7571 - recall_5: 0.4223 - val_loss: 0.3882 - val_accuracy: 0.7639 - val_recall_5: 0.4419\n",
      "Epoch 46/100\n",
      "548/548 [==============================] - 6s 9ms/step - loss: 0.3916 - accuracy: 0.7560 - recall_5: 0.4211 - val_loss: 0.3923 - val_accuracy: 0.7566 - val_recall_5: 0.4163\n",
      "Epoch 47/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3909 - accuracy: 0.7558 - recall_5: 0.4174 - val_loss: 0.3906 - val_accuracy: 0.7544 - val_recall_5: 0.4102\n",
      "Epoch 48/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.3916 - accuracy: 0.7562 - recall_5: 0.4229 - val_loss: 0.3912 - val_accuracy: 0.7562 - val_recall_5: 0.4202\n",
      "Epoch 49/100\n",
      "548/548 [==============================] - 5s 8ms/step - loss: 0.3906 - accuracy: 0.7574 - recall_5: 0.4243 - val_loss: 0.3960 - val_accuracy: 0.7567 - val_recall_5: 0.4300\n",
      "Epoch 50/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3895 - accuracy: 0.7586 - recall_5: 0.4252 - val_loss: 0.3912 - val_accuracy: 0.7539 - val_recall_5: 0.4173\n",
      "Epoch 51/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3905 - accuracy: 0.7565 - recall_5: 0.4215 - val_loss: 0.3893 - val_accuracy: 0.7578 - val_recall_5: 0.4349\n",
      "Epoch 52/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.3899 - accuracy: 0.7578 - recall_5: 0.4268 - val_loss: 0.3867 - val_accuracy: 0.7586 - val_recall_5: 0.4192\n",
      "Epoch 53/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3895 - accuracy: 0.7594 - recall_5: 0.4317 - val_loss: 0.3911 - val_accuracy: 0.7580 - val_recall_5: 0.4307\n",
      "Epoch 54/100\n",
      "548/548 [==============================] - 8s 14ms/step - loss: 0.3884 - accuracy: 0.7598 - recall_5: 0.4307 - val_loss: 0.3852 - val_accuracy: 0.7581 - val_recall_5: 0.4267\n",
      "Epoch 55/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.3893 - accuracy: 0.7584 - recall_5: 0.4307 - val_loss: 0.3844 - val_accuracy: 0.7589 - val_recall_5: 0.4269\n",
      "Epoch 56/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3890 - accuracy: 0.7569 - recall_5: 0.4276 - val_loss: 0.3871 - val_accuracy: 0.7633 - val_recall_5: 0.4336\n",
      "Epoch 57/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3886 - accuracy: 0.7597 - recall_5: 0.4313 - val_loss: 0.3892 - val_accuracy: 0.7592 - val_recall_5: 0.4362\n",
      "Epoch 58/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.3888 - accuracy: 0.7595 - recall_5: 0.4315 - val_loss: 0.3892 - val_accuracy: 0.7611 - val_recall_5: 0.4290\n",
      "Epoch 59/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.3879 - accuracy: 0.7603 - recall_5: 0.4342 - val_loss: 0.3853 - val_accuracy: 0.7609 - val_recall_5: 0.4404\n",
      "Epoch 60/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3861 - accuracy: 0.7601 - recall_5: 0.4335 - val_loss: 0.3910 - val_accuracy: 0.7607 - val_recall_5: 0.4324\n",
      "Epoch 61/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.3876 - accuracy: 0.7600 - recall_5: 0.4312 - val_loss: 0.3904 - val_accuracy: 0.7583 - val_recall_5: 0.4321\n",
      "Epoch 62/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.3877 - accuracy: 0.7624 - recall_5: 0.4343 - val_loss: 0.3850 - val_accuracy: 0.7610 - val_recall_5: 0.4508\n",
      "Epoch 63/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3875 - accuracy: 0.7619 - recall_5: 0.4356 - val_loss: 0.3867 - val_accuracy: 0.7633 - val_recall_5: 0.4338\n",
      "Epoch 64/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3870 - accuracy: 0.7613 - recall_5: 0.4341 - val_loss: 0.3881 - val_accuracy: 0.7621 - val_recall_5: 0.4392\n",
      "Epoch 65/100\n",
      "548/548 [==============================] - 9s 15ms/step - loss: 0.3857 - accuracy: 0.7642 - recall_5: 0.4345 - val_loss: 0.3839 - val_accuracy: 0.7609 - val_recall_5: 0.4354\n",
      "Epoch 66/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3861 - accuracy: 0.7636 - recall_5: 0.4381 - val_loss: 0.3836 - val_accuracy: 0.7636 - val_recall_5: 0.4445\n",
      "Epoch 67/100\n",
      "548/548 [==============================] - 6s 9ms/step - loss: 0.3871 - accuracy: 0.7617 - recall_5: 0.4378 - val_loss: 0.3872 - val_accuracy: 0.7626 - val_recall_5: 0.4368\n",
      "Epoch 68/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.3866 - accuracy: 0.7611 - recall_5: 0.4405 - val_loss: 0.3859 - val_accuracy: 0.7628 - val_recall_5: 0.4418\n",
      "Epoch 69/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3865 - accuracy: 0.7610 - recall_5: 0.4342 - val_loss: 0.3909 - val_accuracy: 0.7621 - val_recall_5: 0.4219\n",
      "Epoch 70/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3859 - accuracy: 0.7637 - recall_5: 0.4388 - val_loss: 0.3867 - val_accuracy: 0.7611 - val_recall_5: 0.4386\n",
      "Epoch 71/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3851 - accuracy: 0.7634 - recall_5: 0.4422 - val_loss: 0.3882 - val_accuracy: 0.7657 - val_recall_5: 0.4453\n",
      "Epoch 72/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.3855 - accuracy: 0.7616 - recall_5: 0.4378 - val_loss: 0.3888 - val_accuracy: 0.7637 - val_recall_5: 0.4344\n",
      "Epoch 73/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3847 - accuracy: 0.7623 - recall_5: 0.4370 - val_loss: 0.3765 - val_accuracy: 0.7679 - val_recall_5: 0.4484\n",
      "Epoch 74/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3858 - accuracy: 0.7625 - recall_5: 0.4395 - val_loss: 0.3775 - val_accuracy: 0.7622 - val_recall_5: 0.4242\n",
      "Epoch 75/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3843 - accuracy: 0.7637 - recall_5: 0.4401 - val_loss: 0.3859 - val_accuracy: 0.7607 - val_recall_5: 0.4369\n",
      "Epoch 76/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.3855 - accuracy: 0.7638 - recall_5: 0.4451 - val_loss: 0.3840 - val_accuracy: 0.7596 - val_recall_5: 0.4462\n",
      "Epoch 77/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3859 - accuracy: 0.7619 - recall_5: 0.4368 - val_loss: 0.3828 - val_accuracy: 0.7630 - val_recall_5: 0.4396\n",
      "Epoch 78/100\n",
      "548/548 [==============================] - 8s 13ms/step - loss: 0.3849 - accuracy: 0.7629 - recall_5: 0.4388 - val_loss: 0.3827 - val_accuracy: 0.7696 - val_recall_5: 0.4470\n",
      "Epoch 79/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.3856 - accuracy: 0.7620 - recall_5: 0.4394 - val_loss: 0.3853 - val_accuracy: 0.7635 - val_recall_5: 0.4395\n",
      "Epoch 80/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.3840 - accuracy: 0.7636 - recall_5: 0.4420 - val_loss: 0.3765 - val_accuracy: 0.7653 - val_recall_5: 0.4351\n",
      "Epoch 81/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3841 - accuracy: 0.7632 - recall_5: 0.4396 - val_loss: 0.3824 - val_accuracy: 0.7653 - val_recall_5: 0.4321\n",
      "Epoch 82/100\n",
      "548/548 [==============================] - 7s 11ms/step - loss: 0.3841 - accuracy: 0.7644 - recall_5: 0.4419 - val_loss: 0.3856 - val_accuracy: 0.7644 - val_recall_5: 0.4455\n",
      "Epoch 83/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3845 - accuracy: 0.7625 - recall_5: 0.4428 - val_loss: 0.3849 - val_accuracy: 0.7600 - val_recall_5: 0.4321\n",
      "Epoch 84/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3828 - accuracy: 0.7651 - recall_5: 0.4441 - val_loss: 0.3856 - val_accuracy: 0.7648 - val_recall_5: 0.4424\n",
      "Epoch 85/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3839 - accuracy: 0.7653 - recall_5: 0.4454 - val_loss: 0.3842 - val_accuracy: 0.7666 - val_recall_5: 0.4395\n",
      "Epoch 86/100\n",
      "548/548 [==============================] - 7s 12ms/step - loss: 0.3845 - accuracy: 0.7631 - recall_5: 0.4414 - val_loss: 0.3849 - val_accuracy: 0.7603 - val_recall_5: 0.4295\n",
      "Epoch 87/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.3848 - accuracy: 0.7627 - recall_5: 0.4409 - val_loss: 0.3807 - val_accuracy: 0.7646 - val_recall_5: 0.4392\n",
      "Epoch 88/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.3833 - accuracy: 0.7629 - recall_5: 0.4403 - val_loss: 0.3782 - val_accuracy: 0.7644 - val_recall_5: 0.4470\n",
      "Epoch 89/100\n",
      "548/548 [==============================] - 7s 13ms/step - loss: 0.3842 - accuracy: 0.7629 - recall_5: 0.4394 - val_loss: 0.3802 - val_accuracy: 0.7603 - val_recall_5: 0.4459\n",
      "Epoch 90/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3844 - accuracy: 0.7638 - recall_5: 0.4402 - val_loss: 0.3805 - val_accuracy: 0.7629 - val_recall_5: 0.4381\n",
      "Epoch 91/100\n",
      "548/548 [==============================] - 5s 9ms/step - loss: 0.3847 - accuracy: 0.7647 - recall_5: 0.4440 - val_loss: 0.3808 - val_accuracy: 0.7626 - val_recall_5: 0.4386\n",
      "Epoch 92/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3840 - accuracy: 0.7616 - recall_5: 0.4352 - val_loss: 0.3843 - val_accuracy: 0.7642 - val_recall_5: 0.4401\n",
      "Epoch 93/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.3829 - accuracy: 0.7630 - recall_5: 0.4406 - val_loss: 0.3818 - val_accuracy: 0.7654 - val_recall_5: 0.4479\n",
      "Epoch 94/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3821 - accuracy: 0.7635 - recall_5: 0.4416 - val_loss: 0.3806 - val_accuracy: 0.7625 - val_recall_5: 0.4413\n",
      "Epoch 95/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3826 - accuracy: 0.7617 - recall_5: 0.4411 - val_loss: 0.3872 - val_accuracy: 0.7612 - val_recall_5: 0.4498\n",
      "Epoch 96/100\n",
      "548/548 [==============================] - 6s 11ms/step - loss: 0.3809 - accuracy: 0.7638 - recall_5: 0.4444 - val_loss: 0.3860 - val_accuracy: 0.7641 - val_recall_5: 0.4536\n",
      "Epoch 97/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3831 - accuracy: 0.7656 - recall_5: 0.4446 - val_loss: 0.3861 - val_accuracy: 0.7574 - val_recall_5: 0.4320\n",
      "Epoch 98/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3829 - accuracy: 0.7631 - recall_5: 0.4392 - val_loss: 0.3808 - val_accuracy: 0.7626 - val_recall_5: 0.4354\n",
      "Epoch 99/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3808 - accuracy: 0.7651 - recall_5: 0.4463 - val_loss: 0.3795 - val_accuracy: 0.7662 - val_recall_5: 0.4428\n",
      "Epoch 100/100\n",
      "548/548 [==============================] - 6s 10ms/step - loss: 0.3837 - accuracy: 0.7645 - recall_5: 0.4479 - val_loss: 0.3793 - val_accuracy: 0.7640 - val_recall_5: 0.4384\n",
      "Model training finished.\n",
      "Evaluating model performance...\n",
      "97/97 [==============================] - 2s 7ms/step - loss: 0.3790 - accuracy: 0.7679 - recall_5: 0.4550\n",
      "Test Accuracy: 76.79%\n",
      "Test Recall: 45.50%\n"
     ]
    }
   ],
   "source": [
    "#Keep our negative_loglikelihood() function but use it with the Bernoulli distribution\n",
    "def negative_loglikelihood(targets, estimated_distribution):\n",
    "    return -estimated_distribution.log_prob(tf.cast(targets, tf.float32))\n",
    "\n",
    "\n",
    "num_epochs = 1000\n",
    "prob_bnn_model = create_probablistic_bnn_model(train_size)\n",
    "run_experiment(prob_bnn_model, negative_loglikelihood, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f826b033-09ea-4167-9324-d4ce36b41c00",
   "metadata": {},
   "source": [
    "Now let's produce an output from the model given the test examples. The output is now a distribution, and we can use its mean and variance to compute the confidence intervals (CI) of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee100e08-345f-4fb6-8919-88878ec6dbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probability: 0.06 - Actual: 0.0\n",
      "Predicted probability: 0.12 - Actual: 0.0\n",
      "Predicted probability: 0.15 - Actual: 0.0\n",
      "Predicted probability: 0.06 - Actual: 0.0\n",
      "Predicted probability: 0.31 - Actual: 0.0\n",
      "Predicted probability: 0.24 - Actual: 0.0\n",
      "Predicted probability: 0.12 - Actual: 0.0\n",
      "Predicted probability: 0.09 - Actual: 0.0\n",
      "Predicted probability: 0.05 - Actual: 0.0\n",
      "Predicted probability: 0.48 - Actual: 1.0\n"
     ]
    }
   ],
   "source": [
    "#To get probabilities from the Bernoulli distribution:\n",
    "prediction_distribution = prob_bnn_model(examples)\n",
    "prediction_mean = prediction_distribution.mean().numpy().flatten().tolist()\n",
    "\n",
    "# You won’t have .stddev() or .mean ± 1.96 * stddev like in the Normal case. Instead, you can:\n",
    "# sample multiple times from the distribution\n",
    "# report percentiles (like 5%–95%) to express uncertainty\n",
    "\n",
    "\n",
    "\n",
    "for idx in range(sample):\n",
    "    prob = prediction_mean[idx]\n",
    "    print(f\"Predicted probability: {round(prob, 2)} - Actual: {targets[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e72f6a99-eff2-4a5e-aefa-a9f3d14d1a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.05999999865889549 - 5th percentile: 0.0 - 95th percentile: 1.0 - Actual: 0.0\n",
      "Mean: 0.11999999731779099 - 5th percentile: 0.0 - 95th percentile: 1.0 - Actual: 0.0\n",
      "Mean: 0.15000000596046448 - 5th percentile: 0.0 - 95th percentile: 1.0 - Actual: 0.0\n",
      "Mean: 0.05999999865889549 - 5th percentile: 0.0 - 95th percentile: 1.0 - Actual: 0.0\n",
      "Mean: 0.3100000023841858 - 5th percentile: 0.0 - 95th percentile: 1.0 - Actual: 0.0\n",
      "Mean: 0.23999999463558197 - 5th percentile: 0.0 - 95th percentile: 1.0 - Actual: 0.0\n",
      "Mean: 0.11999999731779099 - 5th percentile: 0.0 - 95th percentile: 1.0 - Actual: 0.0\n",
      "Mean: 0.09000000357627869 - 5th percentile: 0.0 - 95th percentile: 1.0 - Actual: 0.0\n",
      "Mean: 0.05000000074505806 - 5th percentile: 0.0 - 95th percentile: 0.0 - Actual: 0.0\n",
      "Mean: 0.47999998927116394 - 5th percentile: 0.0 - 95th percentile: 1.0 - Actual: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Sample multiple times from the Bernoulli distributions\n",
    "samples = []\n",
    "num_samples = 100\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    samples.append(prob_bnn_model(examples).sample().numpy().flatten())\n",
    "\n",
    "# Shape: (num_samples, batch_size)\n",
    "samples_array = np.array(samples)\n",
    "\n",
    "# Compute percentiles\n",
    "p5 = np.percentile(samples_array, 5, axis=0)\n",
    "p95 = np.percentile(samples_array, 95, axis=0)\n",
    "mean_probs = prediction_distribution.mean().numpy().flatten()\n",
    "\n",
    "for idx in range(sample):\n",
    "    print(\n",
    "        f\"Mean: {round(mean_probs[idx], 2)} - \"\n",
    "        f\"5th percentile: {round(p5[idx], 2)} - \"\n",
    "        f\"95th percentile: {round(p95[idx], 2)} - \"\n",
    "        f\"Actual: {targets[idx]}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1de17-04bb-4004-b4df-e63611335de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
